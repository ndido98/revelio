{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Revelio Documentation : https://ndido98.github.io/revelio Source Code : https://github.com/ndido98/revelio PyPI : https://pypi.org/project/revelio/ A declarative framework for Morphing Attack Detection experiments Installation git clone git@github.com:ndido98/revelio cd revelio poetry install poetry run revelio Development Clone this repository Requirements: Poetry Python 3.10+ Create a virtual environment and install the dependencies poetry install Activate the virtual environment poetry shell Testing pytest Documentation The documentation is automatically generated from the content of the docs directory and from the docstrings of the public signatures of the source code. The documentation is updated and published as a Github project page automatically as part each release. Pre-commit Pre-commit hooks run all the auto-formatters (e.g. black , isort ), linters (e.g. mypy , flake8 ), and other quality checks to make sure the changeset is in good shape before a commit/push happens. You can install the hooks with (runs for each commit): pre-commit install pre-commit install -t commit-msg Or if you want e.g. want to run all checks manually for all files: pre-commit run --all-files This project was generated using the wolt-python-package-cookiecutter template.","title":"Introduction"},{"location":"#revelio","text":"Documentation : https://ndido98.github.io/revelio Source Code : https://github.com/ndido98/revelio PyPI : https://pypi.org/project/revelio/ A declarative framework for Morphing Attack Detection experiments","title":"Revelio"},{"location":"#installation","text":"git clone git@github.com:ndido98/revelio cd revelio poetry install poetry run revelio","title":"Installation"},{"location":"#development","text":"Clone this repository Requirements: Poetry Python 3.10+ Create a virtual environment and install the dependencies poetry install Activate the virtual environment poetry shell","title":"Development"},{"location":"#testing","text":"pytest","title":"Testing"},{"location":"#documentation","text":"The documentation is automatically generated from the content of the docs directory and from the docstrings of the public signatures of the source code. The documentation is updated and published as a Github project page automatically as part each release.","title":"Documentation"},{"location":"#pre-commit","text":"Pre-commit hooks run all the auto-formatters (e.g. black , isort ), linters (e.g. mypy , flake8 ), and other quality checks to make sure the changeset is in good shape before a commit/push happens. You can install the hooks with (runs for each commit): pre-commit install pre-commit install -t commit-msg Or if you want e.g. want to run all checks manually for all files: pre-commit run --all-files This project was generated using the wolt-python-package-cookiecutter template.","title":"Pre-commit"},{"location":"changelog/","text":"1.0.4 (2022-11-20) Bug Fixes deps: update dependency numpy to v1.23.5 ( 061aea3 ) 1.0.3 (2022-11-09) Bug Fixes deps: update dependency tensorboard to ~2.11.0 ( c2bdf22 ) 1.0.2 (2022-11-04) Bug Fixes deps: update dependency wandb to v0.13.5 ( 2fa7a78 ) 1.0.1 (2022-11-03) Bug Fixes deps: update dependency matplotlib to v3.6.2 ( e192a41 ) 1.0.0 (2022-11-02) Features add logging ( 474f39f ) augmentation: add applies_to field ( 8a1a21e ) augmentation: add augmentation steps ( 2eb2b8e ) callbacks: add early stopping ( ad48f03 ) callbacks: add memory profiling to tensorboard ( 5fdd28f ) callbacks: add model checkpoint ( b5ffef8 ) callbacks: add steps count ( 13b7ea4 ) callbacks: add tensorboard batch viz, graph ( c7c868e ) callbacks: add tensorboard callback ( a86ddeb ) cli: add --no-warmup argument to skip warmup ( c9fce89 ) cli: add cli argparser ( ac5cc8c ) cli: add configurable warmup workers count ( 171bc21 ) cli: add model fitting to cli ( 21e0d0c ) cli: avoid creating train/val workers when only inferencing ( 0258090 ) config: add config model ( 6060d89 ) config: add configurable seed ( 0f43c1a ) config: add templating to scores files path ( 1a2c3e5 ) dataset: add check to make sure all elements have the same number of x ( 97993c9 ) dataset: add dataset element object ( 4754cfb ) dataset: add dataset factory and torch dataset ( c1080f9 ) dataset: add dataset loader ( 9627071 ) dataset: add explicit loader with args ( e105f53 ) dataset: add length ( fec1bae ) dataset: add stats printing ( 8bc2a73 ) dataset: add warmup function ( 3b78208 ) dataset: create testing groups and rework splitting ( ac433b3 ) face-detection: add dlib detector ( b78add1 ) face-detection: add face detector module ( 3767762 ) face-detection: add opencv and mtcnn detectors ( cf0cc4e ) feature-extraction: add feature extractors ( 2dafd04 ) loaders: add biometix morphed loader ( 1ecc55a ) loaders: add morphdb loader ( 6de92b8 ) loaders: add pmdb loader ( a74c60b ) loaders: add several loaders ( 553f258 ) losses: add adam ( 56992b3 ) metrics: add accuracy ( 2ebd862 ) metrics: add eer and bpcer@apcer ( 0f25bc7 ) metrics: add epoch_* metrics for tensorboard, checkpoint and early stopping callbacks ( 212351a ) metrics: add metrics ( 7938b00 ) metrics: add tpr and tnr ( cea5757 ) metrics: allow multiple values in one metric ( e45cddd ) metrics: expose device in which metrics are run ( c50a2fc ) model: add alexnet, vgg and resnet ( 81b603f ) model: add base model class ( ded81c9 ) model: add inception resnet ( 6fbe362 ) model: add mobilenet ( cbdfa5f ) model: add neural network class ( 4d0eff2 ) model: add random guesser ( a4dd65a ) model: add save/load checkpoint ( 097c78f ) model: add squeezenet ( 7e6b44d ) model: add vision transformer ( 1c441ff ) model: move scores file path eval to model score computation ( ecf21f8 ) optimizers: add binary cross entropy ( 3f34637 ) preprocessing: add normalization preprocessing ( 230650a ) preprocessing: add preprocessing phase after feature extraction ( 47c35e4 ) preprocessing: add uint8 -> float32 preprocessing ( 24bf94b ) registry: add - as ignored char ( 1b395c7 ) registry: add transparent registrable classes ( 3da9dd6 ) registry: allow snake case names ( 9925ad9 ) registry: make kwargs with _ assignable only explicitly ( 906c73c ) Bug Fixes add dataset root to dataset element ( c07e304 ) augmentation: change signature of step to take only the image ( bb161e2 ) callbacks: add mkdir to model checkpoint target directory ( dc8c170 ) callbacks: change bona fide to live image reporting ( f25c69b ) callbacks: fix tensorboard graph/image display ( 598ef5a ) callbacks: import early stopping ( d097f89 ) callbacks: remove tensorboard graph ( b3ed308 ) cli: create dataloaders just for warming up for better progress reporting ( bf77bb7 ) cli: disable persistent workers if no workers are used ( 8ff3170 ) cli: use consume to warm up the datasets ( 4a302ef ) config: allow for no preprocessing ( 5df3bfc ) config: change DirectoryPath to str for yet-to-be directories ( b096dbf ) config: fix arg name cannot start with underscore ( 9745aa3 ) config: make args default to empty ( 3ddb895 ) config: validate paths without checking their existence ( 397bad0 ) dataset: add missing y label to yielded element ( cb98631 ) dataset: add randomization of dataset at each epoch ( 7842a32 ) dataset: allow float32 images ( 755c1a2 ) dataset: apply color and channel transposion ( 3e9f853 ) dataset: force gc collection if not loaded from cache ( 45e1353 ) dataset: make face detection offline ( 8c97c30 ) dataset: remove offline processing when not warming up ( eb6ae71 ) dataset: remove warmup function and instead use boolean flag ( 28b42de ) dataset: skip elements if face detection or feature extraction fails ( d67702c ) dataset: use specialized list to avoid memory leaks ( cd3b3ac ) deps: update dependency matplotlib to v3.6.1 ( 429ca2e ) deps: update dependency numpy to v1.23.4 ( 70ab22f ) deps: update dependency scikit-learn to v1.1.3 ( cfc8a7e ) deps: update dependency scipy to v1.9.2 ( 7c84265 ) deps: update dependency scipy to v1.9.3 ( 5b49637 ) face-detection: clip bounding box inside image ( cfadaca ) face-detection: fix numpy arrays not json serializable ( 714ef60 ) face-detection: take biggest bounding box for opencv/mtcnn multiple results ( 8d96535 ) loaders: make amsl loader deterministic ( 5e8b92f ) metrics: adapt bpcer@apcer to be more lax ( 2374786 ) metrics: add conditional to remove nan cases ( 5158c87 ) metrics: improve display of accuracy and bpcer@apcer ( 4a68287 ) metrics: use abstract property for name ( acad600 ) model: add list case to _dict_to_device and fix prediction scores accumulation ( a8f6c47 ) model: add missing definition of resnet model if pretrained ( ef090a7 ) model: apply sigmoid to logits output, remove cumulative loss ( 5b3b2d6 ) model: change scores file format ( 6bc5b9d ) model: fix epoch loading from state dict ( c32ee11 ) model: import neural nets module for registration ( 08fc220 ) model: load metrics from model constructor ( 445cdff ) model: move metrics reset outside batch processing ( bbfbb68 ) model: move predictions to correct device when computing metrics ( 8f5df94 ) nn: don't load callbacks if not training ( c6879b2 ) preprocessing: add interpolation to resize ( 7ee7580 ) preprocessing: redo args validation for normalize ( db7e546 ) registry: fix bug when loading class with args ( 365d942 ) registry: move args sanitization to config ( a690b80 ) use more accurate way of counting steps in data loader ( c726320 )","title":"Changelog"},{"location":"changelog/#104-2022-11-20","text":"","title":"1.0.4 (2022-11-20)"},{"location":"changelog/#bug-fixes","text":"deps: update dependency numpy to v1.23.5 ( 061aea3 )","title":"Bug Fixes"},{"location":"changelog/#103-2022-11-09","text":"","title":"1.0.3 (2022-11-09)"},{"location":"changelog/#bug-fixes_1","text":"deps: update dependency tensorboard to ~2.11.0 ( c2bdf22 )","title":"Bug Fixes"},{"location":"changelog/#102-2022-11-04","text":"","title":"1.0.2 (2022-11-04)"},{"location":"changelog/#bug-fixes_2","text":"deps: update dependency wandb to v0.13.5 ( 2fa7a78 )","title":"Bug Fixes"},{"location":"changelog/#101-2022-11-03","text":"","title":"1.0.1 (2022-11-03)"},{"location":"changelog/#bug-fixes_3","text":"deps: update dependency matplotlib to v3.6.2 ( e192a41 )","title":"Bug Fixes"},{"location":"changelog/#100-2022-11-02","text":"","title":"1.0.0 (2022-11-02)"},{"location":"changelog/#features","text":"add logging ( 474f39f ) augmentation: add applies_to field ( 8a1a21e ) augmentation: add augmentation steps ( 2eb2b8e ) callbacks: add early stopping ( ad48f03 ) callbacks: add memory profiling to tensorboard ( 5fdd28f ) callbacks: add model checkpoint ( b5ffef8 ) callbacks: add steps count ( 13b7ea4 ) callbacks: add tensorboard batch viz, graph ( c7c868e ) callbacks: add tensorboard callback ( a86ddeb ) cli: add --no-warmup argument to skip warmup ( c9fce89 ) cli: add cli argparser ( ac5cc8c ) cli: add configurable warmup workers count ( 171bc21 ) cli: add model fitting to cli ( 21e0d0c ) cli: avoid creating train/val workers when only inferencing ( 0258090 ) config: add config model ( 6060d89 ) config: add configurable seed ( 0f43c1a ) config: add templating to scores files path ( 1a2c3e5 ) dataset: add check to make sure all elements have the same number of x ( 97993c9 ) dataset: add dataset element object ( 4754cfb ) dataset: add dataset factory and torch dataset ( c1080f9 ) dataset: add dataset loader ( 9627071 ) dataset: add explicit loader with args ( e105f53 ) dataset: add length ( fec1bae ) dataset: add stats printing ( 8bc2a73 ) dataset: add warmup function ( 3b78208 ) dataset: create testing groups and rework splitting ( ac433b3 ) face-detection: add dlib detector ( b78add1 ) face-detection: add face detector module ( 3767762 ) face-detection: add opencv and mtcnn detectors ( cf0cc4e ) feature-extraction: add feature extractors ( 2dafd04 ) loaders: add biometix morphed loader ( 1ecc55a ) loaders: add morphdb loader ( 6de92b8 ) loaders: add pmdb loader ( a74c60b ) loaders: add several loaders ( 553f258 ) losses: add adam ( 56992b3 ) metrics: add accuracy ( 2ebd862 ) metrics: add eer and bpcer@apcer ( 0f25bc7 ) metrics: add epoch_* metrics for tensorboard, checkpoint and early stopping callbacks ( 212351a ) metrics: add metrics ( 7938b00 ) metrics: add tpr and tnr ( cea5757 ) metrics: allow multiple values in one metric ( e45cddd ) metrics: expose device in which metrics are run ( c50a2fc ) model: add alexnet, vgg and resnet ( 81b603f ) model: add base model class ( ded81c9 ) model: add inception resnet ( 6fbe362 ) model: add mobilenet ( cbdfa5f ) model: add neural network class ( 4d0eff2 ) model: add random guesser ( a4dd65a ) model: add save/load checkpoint ( 097c78f ) model: add squeezenet ( 7e6b44d ) model: add vision transformer ( 1c441ff ) model: move scores file path eval to model score computation ( ecf21f8 ) optimizers: add binary cross entropy ( 3f34637 ) preprocessing: add normalization preprocessing ( 230650a ) preprocessing: add preprocessing phase after feature extraction ( 47c35e4 ) preprocessing: add uint8 -> float32 preprocessing ( 24bf94b ) registry: add - as ignored char ( 1b395c7 ) registry: add transparent registrable classes ( 3da9dd6 ) registry: allow snake case names ( 9925ad9 ) registry: make kwargs with _ assignable only explicitly ( 906c73c )","title":"Features"},{"location":"changelog/#bug-fixes_4","text":"add dataset root to dataset element ( c07e304 ) augmentation: change signature of step to take only the image ( bb161e2 ) callbacks: add mkdir to model checkpoint target directory ( dc8c170 ) callbacks: change bona fide to live image reporting ( f25c69b ) callbacks: fix tensorboard graph/image display ( 598ef5a ) callbacks: import early stopping ( d097f89 ) callbacks: remove tensorboard graph ( b3ed308 ) cli: create dataloaders just for warming up for better progress reporting ( bf77bb7 ) cli: disable persistent workers if no workers are used ( 8ff3170 ) cli: use consume to warm up the datasets ( 4a302ef ) config: allow for no preprocessing ( 5df3bfc ) config: change DirectoryPath to str for yet-to-be directories ( b096dbf ) config: fix arg name cannot start with underscore ( 9745aa3 ) config: make args default to empty ( 3ddb895 ) config: validate paths without checking their existence ( 397bad0 ) dataset: add missing y label to yielded element ( cb98631 ) dataset: add randomization of dataset at each epoch ( 7842a32 ) dataset: allow float32 images ( 755c1a2 ) dataset: apply color and channel transposion ( 3e9f853 ) dataset: force gc collection if not loaded from cache ( 45e1353 ) dataset: make face detection offline ( 8c97c30 ) dataset: remove offline processing when not warming up ( eb6ae71 ) dataset: remove warmup function and instead use boolean flag ( 28b42de ) dataset: skip elements if face detection or feature extraction fails ( d67702c ) dataset: use specialized list to avoid memory leaks ( cd3b3ac ) deps: update dependency matplotlib to v3.6.1 ( 429ca2e ) deps: update dependency numpy to v1.23.4 ( 70ab22f ) deps: update dependency scikit-learn to v1.1.3 ( cfc8a7e ) deps: update dependency scipy to v1.9.2 ( 7c84265 ) deps: update dependency scipy to v1.9.3 ( 5b49637 ) face-detection: clip bounding box inside image ( cfadaca ) face-detection: fix numpy arrays not json serializable ( 714ef60 ) face-detection: take biggest bounding box for opencv/mtcnn multiple results ( 8d96535 ) loaders: make amsl loader deterministic ( 5e8b92f ) metrics: adapt bpcer@apcer to be more lax ( 2374786 ) metrics: add conditional to remove nan cases ( 5158c87 ) metrics: improve display of accuracy and bpcer@apcer ( 4a68287 ) metrics: use abstract property for name ( acad600 ) model: add list case to _dict_to_device and fix prediction scores accumulation ( a8f6c47 ) model: add missing definition of resnet model if pretrained ( ef090a7 ) model: apply sigmoid to logits output, remove cumulative loss ( 5b3b2d6 ) model: change scores file format ( 6bc5b9d ) model: fix epoch loading from state dict ( c32ee11 ) model: import neural nets module for registration ( 08fc220 ) model: load metrics from model constructor ( 445cdff ) model: move metrics reset outside batch processing ( bbfbb68 ) model: move predictions to correct device when computing metrics ( 8f5df94 ) nn: don't load callbacks if not training ( c6879b2 ) preprocessing: add interpolation to resize ( 7ee7580 ) preprocessing: redo args validation for normalize ( db7e546 ) registry: fix bug when loading class with args ( 365d942 ) registry: move args sanitization to config ( a690b80 ) use more accurate way of counting steps in data loader ( c726320 )","title":"Bug Fixes"},{"location":"config-reference/","text":"Configuration file reference Revelio is a declarative framework for running Morphing Detection Attack experiments, therefore its configuration must be done using a YAML file. This section of the documentation contains all the allowed settings and their description. Main structure The main components of a configuration file are the following: seed (optional) datasets face detection augmentation feature extraction preprocessing experiment The order of the components is not relevant, but it is recommended to follow the order above, as it is the order in which the components are executed.","title":"Configuration file reference"},{"location":"config-reference/#configuration-file-reference","text":"Revelio is a declarative framework for running Morphing Detection Attack experiments, therefore its configuration must be done using a YAML file. This section of the documentation contains all the allowed settings and their description.","title":"Configuration file reference"},{"location":"config-reference/#main-structure","text":"The main components of a configuration file are the following: seed (optional) datasets face detection augmentation feature extraction preprocessing experiment The order of the components is not relevant, but it is recommended to follow the order above, as it is the order in which the components are executed.","title":"Main structure"},{"location":"config-reference/augmentation/","text":"Augmentation You can specify the data augmentation pipeline in the augmentation section of the configuration file. The augmentation pipeline is a list of transformations that are probabilistically applied to the images in the dataset. The transformations are applied in the order they are specified in the configuration file. An example of the most minimal non-empty augmentation pipeline is the following: augmentation : enabled : true steps : - uses : random_crop args : crop_size : 224 The enabled field is a boolean that indicates whether data augmentation should be applied to the dataset. If enabled is false , the augmentation pipeline is ignored and the dataset is not augmented. The steps field is a list of transformations that are applied to the dataset. Each transformation is specified by a dictionary with at least the uses field, which indicates the name of the transformation to use. A step can also have an args field, which is a dictionary of arguments that will be passed to the transformation. Note The uses field is case-insensitive, and all hyphens and underscores are ignored, so RANDOM_CROP , RandomCrop , random-crop and random_crop are all equivalent and will use the same RandomCrop transformation. There are some other fields that can be specified for each augmentation step: probability (optional float, default: 1.0 ): the probability that the transformation will be applied to the image. If probability is 0.5 , the transformation will be applied to half of the images in the dataset. applies_to (optional list of strings or ints, default: all ): the list which contains the indices of the images that the transformation will be applied to, relative to the dataset element (which can have more than one image). If applies_to is all , the transformation will be applied to all images in the dataset element. If applies_to is [0, 2] , the transformation will be applied to the first and third images in the dataset element. There are some special values for applies_to : all : the transformation will be applied to all images in the dataset element (this is the default value); if this value is used, no other value can be specified. probe : the transformation will be applied to the first image in the dataset element, which by convention is the probe image. live : the transformation will be applied to the second image in the dataset element, which by convention is the live image. Note The probability of applying a transformation to an image is on the whole step, not on each image in the dataset element. For instance, if the dataset element has 3 images, and the step has probability: 0.5 and applies_to: [0, 2] , the transformation will be atomically applied to both images with probability 0.5 : either both images will be transformed, or none of them will.","title":"Augmentation"},{"location":"config-reference/augmentation/#augmentation","text":"You can specify the data augmentation pipeline in the augmentation section of the configuration file. The augmentation pipeline is a list of transformations that are probabilistically applied to the images in the dataset. The transformations are applied in the order they are specified in the configuration file. An example of the most minimal non-empty augmentation pipeline is the following: augmentation : enabled : true steps : - uses : random_crop args : crop_size : 224 The enabled field is a boolean that indicates whether data augmentation should be applied to the dataset. If enabled is false , the augmentation pipeline is ignored and the dataset is not augmented. The steps field is a list of transformations that are applied to the dataset. Each transformation is specified by a dictionary with at least the uses field, which indicates the name of the transformation to use. A step can also have an args field, which is a dictionary of arguments that will be passed to the transformation. Note The uses field is case-insensitive, and all hyphens and underscores are ignored, so RANDOM_CROP , RandomCrop , random-crop and random_crop are all equivalent and will use the same RandomCrop transformation. There are some other fields that can be specified for each augmentation step: probability (optional float, default: 1.0 ): the probability that the transformation will be applied to the image. If probability is 0.5 , the transformation will be applied to half of the images in the dataset. applies_to (optional list of strings or ints, default: all ): the list which contains the indices of the images that the transformation will be applied to, relative to the dataset element (which can have more than one image). If applies_to is all , the transformation will be applied to all images in the dataset element. If applies_to is [0, 2] , the transformation will be applied to the first and third images in the dataset element. There are some special values for applies_to : all : the transformation will be applied to all images in the dataset element (this is the default value); if this value is used, no other value can be specified. probe : the transformation will be applied to the first image in the dataset element, which by convention is the probe image. live : the transformation will be applied to the second image in the dataset element, which by convention is the live image. Note The probability of applying a transformation to an image is on the whole step, not on each image in the dataset element. For instance, if the dataset element has 3 images, and the step has probability: 0.5 and applies_to: [0, 2] , the transformation will be atomically applied to both images with probability 0.5 : either both images will be transformed, or none of them will.","title":"Augmentation"},{"location":"config-reference/datasets/","text":"Datasets This section contains the definition of the datasets used in the experiment, during the training and evaluation phases. The most minimal dataset definition is done in the following way: datasets : - name : dataset_name path : /path/to/dataset/root split : train : 0.7 val : 0.1 test : 0.2 - ... The name field is used to identify the dataset in the experiment, and the path field is the path to the root directory of the dataset. The split field is used to define the split of the dataset into training, validation and test sets. The three numbers (each between 0 and 1, both inclusive) represent the percentage of the dataset that will be used for each of the three sets. Note The sum of the three numbers must be at most 1. However, it's not required that the sum of the three numbers is exactly 1: for instance, if you don't want to insert the dataset in the validation set, you can set the val field to 0. The same applies to both train and test . This feature is particularly useful when you want to use only part of a dataset for testing, because having it in its entirety would unbalance the test set. These three fields are required, but you can also add other fields to the dataset definition, as described in the following sections. Dataset loading The way in which a dataset is loaded is defined by the so-called dataset loader , which is a class that scans the dataset root directory and returns a list of items with their respective classes, which are then used to create the whole dataset. By default, the name of the dataset also determines the dataset loader that will be used to load the dataset. For instance, if the dataset name is morphdb , the dataset loader that will be used is MorphDBLoader , which is the default dataset loader for the MorphDB dataset. Note The dataset name is case-insensitive, and all hyphens and underscores are ignored, so MORPHDB , MorphDB , morph-db and morph_db are all equivalent and will use the same MorphDBLoader . If you want to know how to implement a dataset loader, see the reference for further details . Some loaders can also accept additional parameters, which can be specified in the loader.args section of the dataset definition: datasets : - name : dataset_name path : /path/to/dataset/root split : train : 0.7 val : 0.1 test : 0.2 loader : args : arg1 : value1 arg2 : value2 ... - ... The args field is a dictionary of arguments that will be passed to the dataset loader. Sometimes, it is useful to explicitly specify the dataset loader to use, even if the dataset name would normally imply a different loader. This can be done by specifying the loader.name field in the dataset definition: datasets : - name : dataset_name path : /path/to/dataset/root split : train : 0.7 val : 0.1 test : 0.2 loader : name : MyCustomLoader args : arg1 : value1 arg2 : value2 ... - ... Warning Unlike the name field, the loader.name field is case-sensitive, and an exact match is required. Testing groups By default, the model is evaluated on the entirety of the test set. Sometimes it is useful to evaluate the performance of a model only on a subset of the test set, rather than on its entirety. Therefore, you can assign a dataset to multiple testing groups, and the metrics will be computed for each group separately. To do so, you can specify the testing_groups field in the dataset definition: datasets : - name : dataset_name path : /path/to/dataset/root split : train : 0.7 val : 0.1 test : 0.2 testing_groups : - group1 - group2 - ... - ... Note The testing_groups field is ignored if the dataset is not in the test set. The model will be evaluated on each of the groups separately, and on the whole test set. Warning Make sure that each group contains at least one item for each class, otherwise some metrics such as EER and BPCER@APCER may not be computed.","title":"Datasets"},{"location":"config-reference/datasets/#datasets","text":"This section contains the definition of the datasets used in the experiment, during the training and evaluation phases. The most minimal dataset definition is done in the following way: datasets : - name : dataset_name path : /path/to/dataset/root split : train : 0.7 val : 0.1 test : 0.2 - ... The name field is used to identify the dataset in the experiment, and the path field is the path to the root directory of the dataset. The split field is used to define the split of the dataset into training, validation and test sets. The three numbers (each between 0 and 1, both inclusive) represent the percentage of the dataset that will be used for each of the three sets. Note The sum of the three numbers must be at most 1. However, it's not required that the sum of the three numbers is exactly 1: for instance, if you don't want to insert the dataset in the validation set, you can set the val field to 0. The same applies to both train and test . This feature is particularly useful when you want to use only part of a dataset for testing, because having it in its entirety would unbalance the test set. These three fields are required, but you can also add other fields to the dataset definition, as described in the following sections.","title":"Datasets"},{"location":"config-reference/datasets/#dataset-loading","text":"The way in which a dataset is loaded is defined by the so-called dataset loader , which is a class that scans the dataset root directory and returns a list of items with their respective classes, which are then used to create the whole dataset. By default, the name of the dataset also determines the dataset loader that will be used to load the dataset. For instance, if the dataset name is morphdb , the dataset loader that will be used is MorphDBLoader , which is the default dataset loader for the MorphDB dataset. Note The dataset name is case-insensitive, and all hyphens and underscores are ignored, so MORPHDB , MorphDB , morph-db and morph_db are all equivalent and will use the same MorphDBLoader . If you want to know how to implement a dataset loader, see the reference for further details . Some loaders can also accept additional parameters, which can be specified in the loader.args section of the dataset definition: datasets : - name : dataset_name path : /path/to/dataset/root split : train : 0.7 val : 0.1 test : 0.2 loader : args : arg1 : value1 arg2 : value2 ... - ... The args field is a dictionary of arguments that will be passed to the dataset loader. Sometimes, it is useful to explicitly specify the dataset loader to use, even if the dataset name would normally imply a different loader. This can be done by specifying the loader.name field in the dataset definition: datasets : - name : dataset_name path : /path/to/dataset/root split : train : 0.7 val : 0.1 test : 0.2 loader : name : MyCustomLoader args : arg1 : value1 arg2 : value2 ... - ... Warning Unlike the name field, the loader.name field is case-sensitive, and an exact match is required.","title":"Dataset loading"},{"location":"config-reference/datasets/#testing-groups","text":"By default, the model is evaluated on the entirety of the test set. Sometimes it is useful to evaluate the performance of a model only on a subset of the test set, rather than on its entirety. Therefore, you can assign a dataset to multiple testing groups, and the metrics will be computed for each group separately. To do so, you can specify the testing_groups field in the dataset definition: datasets : - name : dataset_name path : /path/to/dataset/root split : train : 0.7 val : 0.1 test : 0.2 testing_groups : - group1 - group2 - ... - ... Note The testing_groups field is ignored if the dataset is not in the test set. The model will be evaluated on each of the groups separately, and on the whole test set. Warning Make sure that each group contains at least one item for each class, otherwise some metrics such as EER and BPCER@APCER may not be computed.","title":"Testing groups"},{"location":"config-reference/experiment/","text":"Experiment The experiment section of the configuration file contains the settings that are used to run the experiment. experiment : batch_size : 64 model : name : model-name args : arg1 : value1 arg2 : value2 ... training : enabled : true args : arg1 : value1 arg2 : value2 ... scores : bona_fide : /path/to/bona_fide_scores.txt morphed : /path/to/morphed_scores.txt metrics : - name : metric1 args : arg1 : value1 arg2 : value2 - name : metric2 - ... While many of the settings vary according to the model used, there are some settings that are common to all models. The batch_size setting specifies the batch size to use when training the model. The model setting specifies the model to use. It has two keys: name , which contains the name of the model, and args , which contains the arguments that will be passed when creating the model. Inside the model setting you can specify the checkpoint field, which contains the path to a checkpoint file. If this field is specified, the model will be loaded from the checkpoint file instead of being created from scratch. The training setting specifies the training settings. It has two keys: enabled , which is a boolean that specifies whether to train the model, and args , which contains the arguments that will be passed when training the model. If the enabled field is set to false , the model will not be trained, and the model specified in the model setting will run only in inference mode. Each model has its own set of training arguments. For instance, a neural network has a much more complicated set of training arguments than a simple linear model. The scores setting specifies the paths to the files containing the scores for the bona fide and morphed images. The scores are the result of the model evaluation on the test set images. The metrics setting specifies the metrics to use to evaluate the model. It contains a list of metrics, each of which has a name and an optional args field. Available models There are two main models already available in Revelio: a neural network and a random guesser. Neural network The configuration of a neural network is quite complex, and it is described in the Neural network page. Random guesser The random guesser is a simple model that always returns a random score between 0 and 1. The random guesser has no arguments. Available metrics There are several metrics already available in Revelio: a complete list can be found in the Metrics page.","title":"Experiment"},{"location":"config-reference/experiment/#experiment","text":"The experiment section of the configuration file contains the settings that are used to run the experiment. experiment : batch_size : 64 model : name : model-name args : arg1 : value1 arg2 : value2 ... training : enabled : true args : arg1 : value1 arg2 : value2 ... scores : bona_fide : /path/to/bona_fide_scores.txt morphed : /path/to/morphed_scores.txt metrics : - name : metric1 args : arg1 : value1 arg2 : value2 - name : metric2 - ... While many of the settings vary according to the model used, there are some settings that are common to all models. The batch_size setting specifies the batch size to use when training the model. The model setting specifies the model to use. It has two keys: name , which contains the name of the model, and args , which contains the arguments that will be passed when creating the model. Inside the model setting you can specify the checkpoint field, which contains the path to a checkpoint file. If this field is specified, the model will be loaded from the checkpoint file instead of being created from scratch. The training setting specifies the training settings. It has two keys: enabled , which is a boolean that specifies whether to train the model, and args , which contains the arguments that will be passed when training the model. If the enabled field is set to false , the model will not be trained, and the model specified in the model setting will run only in inference mode. Each model has its own set of training arguments. For instance, a neural network has a much more complicated set of training arguments than a simple linear model. The scores setting specifies the paths to the files containing the scores for the bona fide and morphed images. The scores are the result of the model evaluation on the test set images. The metrics setting specifies the metrics to use to evaluate the model. It contains a list of metrics, each of which has a name and an optional args field.","title":"Experiment"},{"location":"config-reference/experiment/#available-models","text":"There are two main models already available in Revelio: a neural network and a random guesser.","title":"Available models"},{"location":"config-reference/experiment/#neural-network","text":"The configuration of a neural network is quite complex, and it is described in the Neural network page.","title":"Neural network"},{"location":"config-reference/experiment/#random-guesser","text":"The random guesser is a simple model that always returns a random score between 0 and 1. The random guesser has no arguments.","title":"Random guesser"},{"location":"config-reference/experiment/#available-metrics","text":"There are several metrics already available in Revelio: a complete list can be found in the Metrics page.","title":"Available metrics"},{"location":"config-reference/experiment/metrics/","text":"Metrics There are several metrics already available in Revelio: Accuracy True positive rate True negative rate BPCER@APCER EER No metric has any arguments, except for the following: BPCER@APCER The BPCER@APCER metric has the following arguments: thresholds (required list of floats): the thresholds to use to compute the BPCER@APCER metric. The most used thresholds are 0.1, 0.05, 0.01 and 0.001.","title":"Metrics"},{"location":"config-reference/experiment/metrics/#metrics","text":"There are several metrics already available in Revelio: Accuracy True positive rate True negative rate BPCER@APCER EER No metric has any arguments, except for the following:","title":"Metrics"},{"location":"config-reference/experiment/metrics/#bpcerapcer","text":"The BPCER@APCER metric has the following arguments: thresholds (required list of floats): the thresholds to use to compute the BPCER@APCER metric. The most used thresholds are 0.1, 0.05, 0.01 and 0.001.","title":"BPCER@APCER"},{"location":"config-reference/experiment/neural-network/","text":"Neural network The neural network model is an abstract model that can be used to create any neural network model. It is then up to the user to specify the architecture of the neural network model. While the args in the model section vary according to the model, the args in the training section are the same for all neural network models. training : enabled : true args : epochs : 50 optimizer : name : SGD args : lr : 0.0005 loss : name : BCEWithLogitsLoss callbacks : - name : callback1 args : arg1 : value1 arg2 : value2 ... - ... The epochs argument specifies the number of epochs to train the model for. The optimizer argument specifies the optimizer to use. It has two keys: name , which contains the name of the optimizer, and args , which contains the arguments that will be passed when creating the optimizer. The loss argument specifies the loss function to use. It has two keys: name , which contains the name of the loss function, and args , which contains the arguments that will be passed when creating the loss function. The callbacks argument specifies the callbacks to use. It is a list of callbacks, each of which has a name and an optional args field. Available optimizers There are some optimizers already available in Revelio: SGD Adam In both optimizers the args field allows the same fields as the corresponding PyTorch optimizer; therefore, at least the lr field must be specified. Available loss functions There are some loss functions already available in Revelio: BCEWithLogitsLoss BCELoss In both loss functions the args field allows the same fields as the corresponding PyTorch loss function. Available callbacks There are some callbacks already available in Revelio: EarlyStopping ModelCheckpoint TensorBoard The details of each callback are described in the following sections. EarlyStopping The EarlyStopping callback stops the training when a monitored quantity has stopped improving. callbacks : - name : EarlyStopping args : monitor : val_loss min_delta : 0.001 patience : 5 direction : min restore_best_weights : true The EarlyStopping callback has the following arguments: monitor (optional string, default: val_loss ): the quantity to be monitored. It can be either loss or any of the metrics specified in the metrics section of the configuration file. If you want to monitor a validation-time metric, prepend the metric name with val_ . min_delta (optional float, default: 0.0 ): the minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta , will count as no improvement. patience (optional int, default: 0 ): the number of epochs with no improvement after which training will be stopped. direction (optional string, default: min ): whether to monitor the quantity in an increasing or decreasing way. It can be either min or max . restore_best_weights (optional bool, default: false ): whether to restore model weights from the epoch with the best value of the monitored quantity. If false , the model weights obtained at the last step of training are used. ModelCheckpoint The ModelCheckpoint callback saves the model after every epoch. callbacks : - name : ModelCheckpoint args : file_path : /path/to/checkpoint.pt monitor : val_loss min_delta : 0.001 direction : min save_best_only : true The ModelCheckpoint callback has the following arguments: file_path (string): the path to the file where the model will be saved. monitor (optional string, default: val_loss ): the quantity to be monitored. It can be either loss or any of the metrics specified in the metrics section of the configuration file. If you want to monitor a validation-time metric, prepend the metric name with val_ . min_delta (optional float, default: 0.0 ): the minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta , will count as no improvement. direction (optional string, default: min ): whether to monitor the quantity in an increasing or decreasing way. It can be either min or max . save_best_only (optional bool, default: false ): whether to save the model only if the monitored quantity has improved. The file_path argument can contain the following placeholders, wrapped around curly braces: {epoch} : the epoch number. {now} : the current date and time. {metric} : the value of the monitored metric (e.g. {val_loss:.4f} ). Formatting can be specified after the metric name, as in the example. For more information on formatting, see the Format String Syntax on the Python documentation . TensorBoard The TensorBoard callback logs the training metrics to TensorBoard. callbacks : - name : TensorBoard args : log_dir : /path/to/logs profile : false The TensorBoard callback has the following arguments: log_dir (string): the path to the directory where the logs will be saved. profile (optional bool, default: False ): whether to profile the training process. The TensorBoard callback reports all the metrics specified in the metrics section of the configuration file, as well as the loss. For each metric, the callback reports the value of the metric at the end of each epoch (with the epoch_ prefix), as well as the value of the metric at the end of each batch, both for training and validation. For example, if the metrics section of the configuration file contains accuracy , the callback will report the following metrics: epoch_accuracy epoch_val_accuracy accuracy val_accuracy Also, at the very first batch of the first epoch, the callback reports the images in the training and validation set, as well as the corresponding labels.","title":"Neural network"},{"location":"config-reference/experiment/neural-network/#neural-network","text":"The neural network model is an abstract model that can be used to create any neural network model. It is then up to the user to specify the architecture of the neural network model. While the args in the model section vary according to the model, the args in the training section are the same for all neural network models. training : enabled : true args : epochs : 50 optimizer : name : SGD args : lr : 0.0005 loss : name : BCEWithLogitsLoss callbacks : - name : callback1 args : arg1 : value1 arg2 : value2 ... - ... The epochs argument specifies the number of epochs to train the model for. The optimizer argument specifies the optimizer to use. It has two keys: name , which contains the name of the optimizer, and args , which contains the arguments that will be passed when creating the optimizer. The loss argument specifies the loss function to use. It has two keys: name , which contains the name of the loss function, and args , which contains the arguments that will be passed when creating the loss function. The callbacks argument specifies the callbacks to use. It is a list of callbacks, each of which has a name and an optional args field.","title":"Neural network"},{"location":"config-reference/experiment/neural-network/#available-optimizers","text":"There are some optimizers already available in Revelio: SGD Adam In both optimizers the args field allows the same fields as the corresponding PyTorch optimizer; therefore, at least the lr field must be specified.","title":"Available optimizers"},{"location":"config-reference/experiment/neural-network/#available-loss-functions","text":"There are some loss functions already available in Revelio: BCEWithLogitsLoss BCELoss In both loss functions the args field allows the same fields as the corresponding PyTorch loss function.","title":"Available loss functions"},{"location":"config-reference/experiment/neural-network/#available-callbacks","text":"There are some callbacks already available in Revelio: EarlyStopping ModelCheckpoint TensorBoard The details of each callback are described in the following sections.","title":"Available callbacks"},{"location":"config-reference/experiment/neural-network/#earlystopping","text":"The EarlyStopping callback stops the training when a monitored quantity has stopped improving. callbacks : - name : EarlyStopping args : monitor : val_loss min_delta : 0.001 patience : 5 direction : min restore_best_weights : true The EarlyStopping callback has the following arguments: monitor (optional string, default: val_loss ): the quantity to be monitored. It can be either loss or any of the metrics specified in the metrics section of the configuration file. If you want to monitor a validation-time metric, prepend the metric name with val_ . min_delta (optional float, default: 0.0 ): the minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta , will count as no improvement. patience (optional int, default: 0 ): the number of epochs with no improvement after which training will be stopped. direction (optional string, default: min ): whether to monitor the quantity in an increasing or decreasing way. It can be either min or max . restore_best_weights (optional bool, default: false ): whether to restore model weights from the epoch with the best value of the monitored quantity. If false , the model weights obtained at the last step of training are used.","title":"EarlyStopping"},{"location":"config-reference/experiment/neural-network/#modelcheckpoint","text":"The ModelCheckpoint callback saves the model after every epoch. callbacks : - name : ModelCheckpoint args : file_path : /path/to/checkpoint.pt monitor : val_loss min_delta : 0.001 direction : min save_best_only : true The ModelCheckpoint callback has the following arguments: file_path (string): the path to the file where the model will be saved. monitor (optional string, default: val_loss ): the quantity to be monitored. It can be either loss or any of the metrics specified in the metrics section of the configuration file. If you want to monitor a validation-time metric, prepend the metric name with val_ . min_delta (optional float, default: 0.0 ): the minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta , will count as no improvement. direction (optional string, default: min ): whether to monitor the quantity in an increasing or decreasing way. It can be either min or max . save_best_only (optional bool, default: false ): whether to save the model only if the monitored quantity has improved. The file_path argument can contain the following placeholders, wrapped around curly braces: {epoch} : the epoch number. {now} : the current date and time. {metric} : the value of the monitored metric (e.g. {val_loss:.4f} ). Formatting can be specified after the metric name, as in the example. For more information on formatting, see the Format String Syntax on the Python documentation .","title":"ModelCheckpoint"},{"location":"config-reference/experiment/neural-network/#tensorboard","text":"The TensorBoard callback logs the training metrics to TensorBoard. callbacks : - name : TensorBoard args : log_dir : /path/to/logs profile : false The TensorBoard callback has the following arguments: log_dir (string): the path to the directory where the logs will be saved. profile (optional bool, default: False ): whether to profile the training process. The TensorBoard callback reports all the metrics specified in the metrics section of the configuration file, as well as the loss. For each metric, the callback reports the value of the metric at the end of each epoch (with the epoch_ prefix), as well as the value of the metric at the end of each batch, both for training and validation. For example, if the metrics section of the configuration file contains accuracy , the callback will report the following metrics: epoch_accuracy epoch_val_accuracy accuracy val_accuracy Also, at the very first batch of the first epoch, the callback reports the images in the training and validation set, as well as the corresponding labels.","title":"TensorBoard"},{"location":"config-reference/face-detection/","text":"Face detection The face detection section of the configuration file contains the settings that are used to detect faces in the images of the dataset, if needed. face_detection : enabled : true output_path : /path/to/face_detection_output algorithm : name : mtcnn_detector args : arg1 : value1 arg2 : value2 ... The enabled field is a boolean that indicates whether face detection should be performed or not. The output_path field is a string that indicates the path where the face detection output should be saved. The algorithm field has two subfields: name specifies the name of the face detector to use, and args is a dictionary of arguments that will be passed to it. Note The name field is case-insensitive, and all hyphens and underscores are ignored, so MTCNN_DETECTOR , MtcnnDetector , mtcnn-detector and mtcnn_detector are all equivalent and will use the same MTCNNDetector . Face detectors There are three face detectors already available in Revelio: * dlib * OpenCV * MTCNN Both dlib and MTCNN also extract facial landmarks, while OpenCV does not. dlib The dlib face detector is based on the dlib library. The dlib face detector has the following arguments: landmark_predictor_path (optional path, default: None ): the path to the file containing the facial landmark predictor model. If None , facial landmarks will not be extracted. The landmark predictor model can be downloaded from the dlib website . face_detection : enabled : true output_path : /path/to/face_detection_output algorithm : name : dlib_detector args : landmark_predictor_path : /path/to/landmark_predictor.dat OpenCV The opencv face detector is based on the OpenCV library. The opencv face detector has the following arguments: classifier_path (required path): the path to the file containing the OpenCV face detector model that the CascadeClassifier will load. The most common model is haarcascade_frontalface_default.xml , which is available on the OpenCV GitHub repository . face_detection : enabled : true output_path : /path/to/face_detection_output algorithm : name : opencv_detector args : classifier_path : /path/to/classifier.xml MTCNN The mtcnn face detector is based on the MTCNN library. The mtcnn face detector has no arguments. face_detection : enabled : true output_path : /path/to/face_detection_output algorithm : name : mtcnn_detector","title":"Face detection"},{"location":"config-reference/face-detection/#face-detection","text":"The face detection section of the configuration file contains the settings that are used to detect faces in the images of the dataset, if needed. face_detection : enabled : true output_path : /path/to/face_detection_output algorithm : name : mtcnn_detector args : arg1 : value1 arg2 : value2 ... The enabled field is a boolean that indicates whether face detection should be performed or not. The output_path field is a string that indicates the path where the face detection output should be saved. The algorithm field has two subfields: name specifies the name of the face detector to use, and args is a dictionary of arguments that will be passed to it. Note The name field is case-insensitive, and all hyphens and underscores are ignored, so MTCNN_DETECTOR , MtcnnDetector , mtcnn-detector and mtcnn_detector are all equivalent and will use the same MTCNNDetector .","title":"Face detection"},{"location":"config-reference/face-detection/#face-detectors","text":"There are three face detectors already available in Revelio: * dlib * OpenCV * MTCNN Both dlib and MTCNN also extract facial landmarks, while OpenCV does not.","title":"Face detectors"},{"location":"config-reference/face-detection/#dlib","text":"The dlib face detector is based on the dlib library. The dlib face detector has the following arguments: landmark_predictor_path (optional path, default: None ): the path to the file containing the facial landmark predictor model. If None , facial landmarks will not be extracted. The landmark predictor model can be downloaded from the dlib website . face_detection : enabled : true output_path : /path/to/face_detection_output algorithm : name : dlib_detector args : landmark_predictor_path : /path/to/landmark_predictor.dat","title":"dlib"},{"location":"config-reference/face-detection/#opencv","text":"The opencv face detector is based on the OpenCV library. The opencv face detector has the following arguments: classifier_path (required path): the path to the file containing the OpenCV face detector model that the CascadeClassifier will load. The most common model is haarcascade_frontalface_default.xml , which is available on the OpenCV GitHub repository . face_detection : enabled : true output_path : /path/to/face_detection_output algorithm : name : opencv_detector args : classifier_path : /path/to/classifier.xml","title":"OpenCV"},{"location":"config-reference/face-detection/#mtcnn","text":"The mtcnn face detector is based on the MTCNN library. The mtcnn face detector has no arguments. face_detection : enabled : true output_path : /path/to/face_detection_output algorithm : name : mtcnn_detector","title":"MTCNN"},{"location":"config-reference/feature-extraction/","text":"Feature extraction The feature extraction section of the configuration file contains the settings that are used to extract features from the images in the dataset. feature_extraction : enabled : false output_path : /path/to/feature_extraction_output algorithms : - name : feature_extractor args : arg1 : value1 arg2 : value2 ... The enabled field is a boolean that indicates whether feature extraction should be performed or not. The output_path field is a string that indicates the path where the feature extraction output should be saved. The algorithms list contains all the algorithms that will be used to extract features of different types from the images in the dataset. Each algorithm has two keys: name , which contains the name of the algorithm, and args , which contains the arguments that will be passed to the algorithm. Note The name field is case-insensitive, and all hyphens and underscores are ignored, so FEATURE_EXTRACTOR , FeatureExtractor , feature-extractor and feature_extractor are all equivalent and will use the same FeatureExtractor algorithm.","title":"Feature extraction"},{"location":"config-reference/feature-extraction/#feature-extraction","text":"The feature extraction section of the configuration file contains the settings that are used to extract features from the images in the dataset. feature_extraction : enabled : false output_path : /path/to/feature_extraction_output algorithms : - name : feature_extractor args : arg1 : value1 arg2 : value2 ... The enabled field is a boolean that indicates whether feature extraction should be performed or not. The output_path field is a string that indicates the path where the feature extraction output should be saved. The algorithms list contains all the algorithms that will be used to extract features of different types from the images in the dataset. Each algorithm has two keys: name , which contains the name of the algorithm, and args , which contains the arguments that will be passed to the algorithm. Note The name field is case-insensitive, and all hyphens and underscores are ignored, so FEATURE_EXTRACTOR , FeatureExtractor , feature-extractor and feature_extractor are all equivalent and will use the same FeatureExtractor algorithm.","title":"Feature extraction"},{"location":"config-reference/preprocessing/","text":"Preprocessing The preprocessing section of the configuration file contains the settings that are used to preprocess the images in the dataset, right before passing them to the model. preprocessing : steps : - uses : step1 args : arg1 : value1 arg2 : value2 ... - ... The steps list contains all the preprocessing steps that will be applied to the images in the dataset. Each step has two keys: uses , which contains the name of the step, and args , which contains the arguments that will be passed to the step. Note The uses field is case-insensitive, and all hyphens and underscores are ignored, so STEP1 , Step1 , step-1 and step_1 are all equivalent and will use the same Step1 step. The transformations are applied in the order they are specified in the configuration file. Preprocessing steps There are some preprocessing steps already available in Revelio. Resize The resize step resizes the images to the specified size. The resize step has the following arguments: width (required int): the width of the resized images. height (required int): the height of the resized images. algorithm (optional string, default: cubic ): the algorithm to use to resize the images. The available algorithms are the same as the ones available in OpenCV: nearest : nearest-neighbor interpolation linear : bilinear interpolation cubic : bicubic interpolation (default) area : resampling using pixel area relation lanczos4 : Lanczos interpolation over 8x8 neighborhood keep_aspect_ratio (optional bool, default: True ): whether to keep the aspect ratio of the images when resizing them. fill_mode (optional string, default: constant ): the strategy used for filling in newly created pixels, which can appear when using the keep_aspect_ratio option. The available strategies are the same as the ones available in OpenCV: constant : the pixels are filled with black (default, e.g. 000000|abcdefgh|000000 ) reflect : the pixels are filled with the reflection of the image (e.g. gfedcb|abcdefgh|gfedcba ) replicate : the pixels are filled with the last pixel of the image (e.g. aaaaaa|abcdefgh|hhhhhhh ) wrap : the pixels are filled with the wrap of the image (e.g. cdefgh|abcdefgh|abcdefg ) To float The to_float step converts the images to floating point images in the range [0, 1] . The to_float step has no arguments. Normalize The normalize step normalizes the images using the specified mean and standard deviation. The normalize step has the following arguments: mean (optional list of floats, default: None ): the mean to use to normalize the images, one element per BGR channel. std (optional list of floats, default: None ): the standard deviation to use to normalize the images, one element per BGR channel. preset (optional string, default: None ): the preset to use to normalize the images. The available presets are: imagenet : the mean and standard deviation used to normalize the images in the ImageNet dataset. Either preset or both mean and std must be specified. Warning Watch out for the order of the channels in the mean and standard deviation values. The order is BGR (i.e. OpenCV convention), not RGB.","title":"Preprocessing"},{"location":"config-reference/preprocessing/#preprocessing","text":"The preprocessing section of the configuration file contains the settings that are used to preprocess the images in the dataset, right before passing them to the model. preprocessing : steps : - uses : step1 args : arg1 : value1 arg2 : value2 ... - ... The steps list contains all the preprocessing steps that will be applied to the images in the dataset. Each step has two keys: uses , which contains the name of the step, and args , which contains the arguments that will be passed to the step. Note The uses field is case-insensitive, and all hyphens and underscores are ignored, so STEP1 , Step1 , step-1 and step_1 are all equivalent and will use the same Step1 step. The transformations are applied in the order they are specified in the configuration file.","title":"Preprocessing"},{"location":"config-reference/preprocessing/#preprocessing-steps","text":"There are some preprocessing steps already available in Revelio.","title":"Preprocessing steps"},{"location":"config-reference/preprocessing/#resize","text":"The resize step resizes the images to the specified size. The resize step has the following arguments: width (required int): the width of the resized images. height (required int): the height of the resized images. algorithm (optional string, default: cubic ): the algorithm to use to resize the images. The available algorithms are the same as the ones available in OpenCV: nearest : nearest-neighbor interpolation linear : bilinear interpolation cubic : bicubic interpolation (default) area : resampling using pixel area relation lanczos4 : Lanczos interpolation over 8x8 neighborhood keep_aspect_ratio (optional bool, default: True ): whether to keep the aspect ratio of the images when resizing them. fill_mode (optional string, default: constant ): the strategy used for filling in newly created pixels, which can appear when using the keep_aspect_ratio option. The available strategies are the same as the ones available in OpenCV: constant : the pixels are filled with black (default, e.g. 000000|abcdefgh|000000 ) reflect : the pixels are filled with the reflection of the image (e.g. gfedcb|abcdefgh|gfedcba ) replicate : the pixels are filled with the last pixel of the image (e.g. aaaaaa|abcdefgh|hhhhhhh ) wrap : the pixels are filled with the wrap of the image (e.g. cdefgh|abcdefgh|abcdefg )","title":"Resize"},{"location":"config-reference/preprocessing/#to-float","text":"The to_float step converts the images to floating point images in the range [0, 1] . The to_float step has no arguments.","title":"To float"},{"location":"config-reference/preprocessing/#normalize","text":"The normalize step normalizes the images using the specified mean and standard deviation. The normalize step has the following arguments: mean (optional list of floats, default: None ): the mean to use to normalize the images, one element per BGR channel. std (optional list of floats, default: None ): the standard deviation to use to normalize the images, one element per BGR channel. preset (optional string, default: None ): the preset to use to normalize the images. The available presets are: imagenet : the mean and standard deviation used to normalize the images in the ImageNet dataset. Either preset or both mean and std must be specified. Warning Watch out for the order of the channels in the mean and standard deviation values. The order is BGR (i.e. OpenCV convention), not RGB.","title":"Normalize"},{"location":"config-reference/seed/","text":"Seed Note This section is optional. The seed is an integer used to initialize the random number generator. This is useful to ensure reproducibility of the experiments. seed : 42 ...","title":"Seed"},{"location":"config-reference/seed/#seed","text":"Note This section is optional. The seed is an integer used to initialize the random number generator. This is useful to ensure reproducibility of the experiments. seed : 42 ...","title":"Seed"},{"location":"reference/SUMMARY/","text":"revelio augmentation step cli config config model augmentation dataset experiment face_detection feature_extraction preprocessing utils dataset dataset dataset_factory descriptors_list element loaders loader loaders face_detection detector dlib_detector mtcnn_detector opencv_detector feature_extraction extractor model metrics accuracy bpcer_at_apcer eer metric tnr tpr utils model nn alexnet callbacks callback early_stopping model_checkpoint tensorboard inception_resnet losses loss losses mobilenet neuralnet optimizers optimizer optimizers resnet squeezenet utils vgg vision_transformer random_guess preprocessing normalize resize step to_float registry registry utils iterators logging random rounding","title":"SUMMARY"},{"location":"reference/revelio/","text":"","title":"revelio"},{"location":"reference/revelio/cli/","text":"","title":"cli"},{"location":"reference/revelio/augmentation/","text":"","title":"augmentation"},{"location":"reference/revelio/augmentation/step/","text":"This module contains the class that defines an augmentation step, from which all augmentation steps inherit. A user can define their own augmentation steps by subclassing this class and overriding the process_element method. AugmentationStep Bases: Registrable An augmentation step is applied to a dataset element with a certain probability. The affected images of the dataset element can be specified with the applies_to parameter in the configuration file. If applies_to is set to \"all\", the augmentation step is applied to all images of the dataset element. If applies_to is set to a list of integers, the augmentation step is applied to the images with the specified indices. The probability parameter specifies the probability (between 0 and 1 inclusive) with which the augmentation step is applied to a dataset element. The process_element method is called for each image of the dataset element that is affected by the augmentation step. An augmentation step must implement the process_element method, which takes an image and returns its augmented version. Only dataset elements which are part of the training set are augmented; validation and test sets are not augmented. Source code in revelio/augmentation/step.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 class AugmentationStep ( Registrable ): \"\"\" An augmentation step is applied to a dataset element with a certain probability. The affected images of the dataset element can be specified with the `applies_to` parameter in the configuration file. If `applies_to` is set to \"all\", the augmentation step is applied to all images of the dataset element. If `applies_to` is set to a list of integers, the augmentation step is applied to the images with the specified indices. The probability parameter specifies the probability (between 0 and 1 inclusive) with which the augmentation step is applied to a dataset element. The process_element method is called for each image of the dataset element that is affected by the augmentation step. An augmentation step must implement the `process_element` method, which takes an image and returns its augmented version. Only dataset elements which are part of the training set are augmented; validation and test sets are not augmented. \"\"\" def __init__ ( self , * , _applies_to : list [ int ] | Literal [ \"all\" ], _probability : float ) -> None : self . _applies_to = _applies_to self . _probability = _probability @abstractmethod def process_element ( self , elem : ElementImage ) -> ElementImage : \"\"\" Processes a single image of a dataset element, and returns its augmented version. Args: elem: The image to be augmented. Returns: The augmented image. \"\"\" raise NotImplementedError # pragma: no cover def process ( self , elem : DatasetElement ) -> DatasetElement : \"\"\" Processes a dataset element, and returns its augmented version. This method should not be overridden by the user, but instead the `process_element` method should be implemented. Args: elem: The dataset element to be augmented. Returns: The augmented dataset element. \"\"\" if random . random () < self . _probability : new_xs = [] for i , x in enumerate ( elem . x ): if self . _applies_to == \"all\" or i in self . _applies_to : new_xs . append ( self . process_element ( x )) else : new_xs . append ( x ) return DatasetElement ( dataset_root_path = elem . dataset_root_path , original_dataset = elem . original_dataset , x = tuple ( new_xs ), y = elem . y , ) else : return elem process ( elem : DatasetElement ) -> DatasetElement Processes a dataset element, and returns its augmented version. This method should not be overridden by the user, but instead the process_element method should be implemented. Parameters: Name Type Description Default elem DatasetElement The dataset element to be augmented. required Returns: Type Description DatasetElement The augmented dataset element. Source code in revelio/augmentation/step.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 def process ( self , elem : DatasetElement ) -> DatasetElement : \"\"\" Processes a dataset element, and returns its augmented version. This method should not be overridden by the user, but instead the `process_element` method should be implemented. Args: elem: The dataset element to be augmented. Returns: The augmented dataset element. \"\"\" if random . random () < self . _probability : new_xs = [] for i , x in enumerate ( elem . x ): if self . _applies_to == \"all\" or i in self . _applies_to : new_xs . append ( self . process_element ( x )) else : new_xs . append ( x ) return DatasetElement ( dataset_root_path = elem . dataset_root_path , original_dataset = elem . original_dataset , x = tuple ( new_xs ), y = elem . y , ) else : return elem process_element ( elem : ElementImage ) -> ElementImage abstractmethod Processes a single image of a dataset element, and returns its augmented version. Parameters: Name Type Description Default elem ElementImage The image to be augmented. required Returns: Type Description ElementImage The augmented image. Source code in revelio/augmentation/step.py 46 47 48 49 50 51 52 53 54 55 56 57 58 @abstractmethod def process_element ( self , elem : ElementImage ) -> ElementImage : \"\"\" Processes a single image of a dataset element, and returns its augmented version. Args: elem: The image to be augmented. Returns: The augmented image. \"\"\" raise NotImplementedError # pragma: no cover","title":"step"},{"location":"reference/revelio/augmentation/step/#revelio.augmentation.step.AugmentationStep","text":"Bases: Registrable An augmentation step is applied to a dataset element with a certain probability. The affected images of the dataset element can be specified with the applies_to parameter in the configuration file. If applies_to is set to \"all\", the augmentation step is applied to all images of the dataset element. If applies_to is set to a list of integers, the augmentation step is applied to the images with the specified indices. The probability parameter specifies the probability (between 0 and 1 inclusive) with which the augmentation step is applied to a dataset element. The process_element method is called for each image of the dataset element that is affected by the augmentation step. An augmentation step must implement the process_element method, which takes an image and returns its augmented version. Only dataset elements which are part of the training set are augmented; validation and test sets are not augmented. Source code in revelio/augmentation/step.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 class AugmentationStep ( Registrable ): \"\"\" An augmentation step is applied to a dataset element with a certain probability. The affected images of the dataset element can be specified with the `applies_to` parameter in the configuration file. If `applies_to` is set to \"all\", the augmentation step is applied to all images of the dataset element. If `applies_to` is set to a list of integers, the augmentation step is applied to the images with the specified indices. The probability parameter specifies the probability (between 0 and 1 inclusive) with which the augmentation step is applied to a dataset element. The process_element method is called for each image of the dataset element that is affected by the augmentation step. An augmentation step must implement the `process_element` method, which takes an image and returns its augmented version. Only dataset elements which are part of the training set are augmented; validation and test sets are not augmented. \"\"\" def __init__ ( self , * , _applies_to : list [ int ] | Literal [ \"all\" ], _probability : float ) -> None : self . _applies_to = _applies_to self . _probability = _probability @abstractmethod def process_element ( self , elem : ElementImage ) -> ElementImage : \"\"\" Processes a single image of a dataset element, and returns its augmented version. Args: elem: The image to be augmented. Returns: The augmented image. \"\"\" raise NotImplementedError # pragma: no cover def process ( self , elem : DatasetElement ) -> DatasetElement : \"\"\" Processes a dataset element, and returns its augmented version. This method should not be overridden by the user, but instead the `process_element` method should be implemented. Args: elem: The dataset element to be augmented. Returns: The augmented dataset element. \"\"\" if random . random () < self . _probability : new_xs = [] for i , x in enumerate ( elem . x ): if self . _applies_to == \"all\" or i in self . _applies_to : new_xs . append ( self . process_element ( x )) else : new_xs . append ( x ) return DatasetElement ( dataset_root_path = elem . dataset_root_path , original_dataset = elem . original_dataset , x = tuple ( new_xs ), y = elem . y , ) else : return elem","title":"AugmentationStep"},{"location":"reference/revelio/augmentation/step/#revelio.augmentation.step.AugmentationStep.process","text":"Processes a dataset element, and returns its augmented version. This method should not be overridden by the user, but instead the process_element method should be implemented. Parameters: Name Type Description Default elem DatasetElement The dataset element to be augmented. required Returns: Type Description DatasetElement The augmented dataset element. Source code in revelio/augmentation/step.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 def process ( self , elem : DatasetElement ) -> DatasetElement : \"\"\" Processes a dataset element, and returns its augmented version. This method should not be overridden by the user, but instead the `process_element` method should be implemented. Args: elem: The dataset element to be augmented. Returns: The augmented dataset element. \"\"\" if random . random () < self . _probability : new_xs = [] for i , x in enumerate ( elem . x ): if self . _applies_to == \"all\" or i in self . _applies_to : new_xs . append ( self . process_element ( x )) else : new_xs . append ( x ) return DatasetElement ( dataset_root_path = elem . dataset_root_path , original_dataset = elem . original_dataset , x = tuple ( new_xs ), y = elem . y , ) else : return elem","title":"process()"},{"location":"reference/revelio/augmentation/step/#revelio.augmentation.step.AugmentationStep.process_element","text":"Processes a single image of a dataset element, and returns its augmented version. Parameters: Name Type Description Default elem ElementImage The image to be augmented. required Returns: Type Description ElementImage The augmented image. Source code in revelio/augmentation/step.py 46 47 48 49 50 51 52 53 54 55 56 57 58 @abstractmethod def process_element ( self , elem : ElementImage ) -> ElementImage : \"\"\" Processes a single image of a dataset element, and returns its augmented version. Args: elem: The image to be augmented. Returns: The augmented image. \"\"\" raise NotImplementedError # pragma: no cover","title":"process_element()"},{"location":"reference/revelio/config/","text":"","title":"config"},{"location":"reference/revelio/config/config/","text":"","title":"config"},{"location":"reference/revelio/config/model/","text":"","title":"model"},{"location":"reference/revelio/config/model/augmentation/","text":"","title":"augmentation"},{"location":"reference/revelio/config/model/dataset/","text":"","title":"dataset"},{"location":"reference/revelio/config/model/experiment/","text":"","title":"experiment"},{"location":"reference/revelio/config/model/face_detection/","text":"","title":"face_detection"},{"location":"reference/revelio/config/model/feature_extraction/","text":"","title":"feature_extraction"},{"location":"reference/revelio/config/model/preprocessing/","text":"","title":"preprocessing"},{"location":"reference/revelio/config/model/utils/","text":"","title":"utils"},{"location":"reference/revelio/dataset/","text":"","title":"dataset"},{"location":"reference/revelio/dataset/dataset/","text":"","title":"dataset"},{"location":"reference/revelio/dataset/dataset_factory/","text":"","title":"dataset_factory"},{"location":"reference/revelio/dataset/descriptors_list/","text":"","title":"descriptors_list"},{"location":"reference/revelio/dataset/element/","text":"DatasetElement An element of the dataset. Attributes: Name Type Description x tuple [ ElementImage , ...] The image(s) of the dataset element. y ElementClass The class of the dataset element. original_dataset str The name of the original dataset from which the element was taken. It is equal to the dataset name specified in the configuration file. dataset_root_path Path The path to the root directory of the dataset. Source code in revelio/dataset/element.py 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 class DatasetElement : \"\"\" An element of the dataset. Attributes: x: The image(s) of the dataset element. y: The class of the dataset element. original_dataset: The name of the original dataset from which the element was taken. It is equal to the dataset name specified in the configuration file. dataset_root_path: The path to the root directory of the dataset. \"\"\" _dataset_root_path : Path _original_dataset : str _x : tuple [ ElementImage , ... ] _y : ElementClass def __init__ ( self , x : tuple [ ElementImage , ... ], y : ElementClass , * , dataset_root_path : Path , original_dataset : str , ) -> None : \"\"\" Creates a new dataset element. Args: x: The image(s) of the dataset element. y: The class of the dataset element. dataset_root_path: The path to the root directory of the dataset. original_dataset: The name of the original dataset from which the element was taken. \"\"\" self . _x = x self . _y = y self . _dataset_root_path = dataset_root_path self . _original_dataset = original_dataset @property def dataset_root_path ( self ) -> Path : \"\"\" Gets the path to the root directory of the dataset. \"\"\" return self . _dataset_root_path @property def original_dataset ( self ) -> str : \"\"\" Gets the name of the original dataset from which the element was taken. \"\"\" return self . _original_dataset @property def x ( self ) -> tuple [ ElementImage , ... ]: \"\"\" Gets the image(s) of the dataset element. \"\"\" return self . _x @property def y ( self ) -> ElementClass : \"\"\" Gets the class of the dataset element. \"\"\" return self . _y def __repr__ ( self ) -> str : return f \"DatasetElement(x= { self . x } , y= { self . y } )\" __init__ ( x : tuple [ ElementImage , ... ], y : ElementClass , * , dataset_root_path : Path , original_dataset : str ) -> None Creates a new dataset element. Parameters: Name Type Description Default x tuple [ ElementImage , ...] The image(s) of the dataset element. required y ElementClass The class of the dataset element. required dataset_root_path Path The path to the root directory of the dataset. required original_dataset str The name of the original dataset from which the element was taken. required Source code in revelio/dataset/element.py 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 def __init__ ( self , x : tuple [ ElementImage , ... ], y : ElementClass , * , dataset_root_path : Path , original_dataset : str , ) -> None : \"\"\" Creates a new dataset element. Args: x: The image(s) of the dataset element. y: The class of the dataset element. dataset_root_path: The path to the root directory of the dataset. original_dataset: The name of the original dataset from which the element was taken. \"\"\" self . _x = x self . _y = y self . _dataset_root_path = dataset_root_path self . _original_dataset = original_dataset dataset_root_path () -> Path property Gets the path to the root directory of the dataset. Source code in revelio/dataset/element.py 191 192 193 194 195 196 @property def dataset_root_path ( self ) -> Path : \"\"\" Gets the path to the root directory of the dataset. \"\"\" return self . _dataset_root_path original_dataset () -> str property Gets the name of the original dataset from which the element was taken. Source code in revelio/dataset/element.py 198 199 200 201 202 203 @property def original_dataset ( self ) -> str : \"\"\" Gets the name of the original dataset from which the element was taken. \"\"\" return self . _original_dataset x () -> tuple [ ElementImage , ... ] property Gets the image(s) of the dataset element. Source code in revelio/dataset/element.py 205 206 207 208 209 210 @property def x ( self ) -> tuple [ ElementImage , ... ]: \"\"\" Gets the image(s) of the dataset element. \"\"\" return self . _x y () -> ElementClass property Gets the class of the dataset element. Source code in revelio/dataset/element.py 212 213 214 215 216 217 @property def y ( self ) -> ElementClass : \"\"\" Gets the class of the dataset element. \"\"\" return self . _y DatasetElementDescriptor A descriptor of a dataset element before it is loaded into memory. Attributes: Name Type Description x tuple [ Path , ...] The path to the image file(s). y ElementClass The class of the dataset element. Source code in revelio/dataset/element.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 class DatasetElementDescriptor : \"\"\" A descriptor of a dataset element before it is loaded into memory. Attributes: x: The path to the image file(s). y: The class of the dataset element. \"\"\" _x : tuple [ Path , ... ] _y : ElementClass _root_path : Path _dataset_name : str def __init__ ( self , x : tuple [ Path , ... ], y : ElementClass ) -> None : \"\"\" Creates a new dataset element descriptor. Args: x: The path to the image file(s). y: The class of the dataset element. \"\"\" self . _x = x self . _y = y @property def x ( self ) -> tuple [ Path , ... ]: \"\"\" Gets the path to the image file(s). \"\"\" return self . _x @property def y ( self ) -> ElementClass : \"\"\" Gets the class of the dataset element. \"\"\" return self . _y def __repr__ ( self ) -> str : return f \"DatasetElementDescriptor(x= { self . x } , y= { self . y } )\" def __eq__ ( self , other : Any ) -> bool : if not isinstance ( other , DatasetElementDescriptor ): return NotImplemented return ( self . x == other . x and self . y == other . y and self . _root_path == other . _root_path and self . _dataset_name == other . _dataset_name ) def __hash__ ( self ) -> int : return hash (( self . x , self . y , self . _root_path , self . _dataset_name )) __init__ ( x : tuple [ Path , ... ], y : ElementClass ) -> None Creates a new dataset element descriptor. Parameters: Name Type Description Default x tuple [ Path , ...] The path to the image file(s). required y ElementClass The class of the dataset element. required Source code in revelio/dataset/element.py 33 34 35 36 37 38 39 40 41 42 def __init__ ( self , x : tuple [ Path , ... ], y : ElementClass ) -> None : \"\"\" Creates a new dataset element descriptor. Args: x: The path to the image file(s). y: The class of the dataset element. \"\"\" self . _x = x self . _y = y x () -> tuple [ Path , ... ] property Gets the path to the image file(s). Source code in revelio/dataset/element.py 44 45 46 47 48 49 @property def x ( self ) -> tuple [ Path , ... ]: \"\"\" Gets the path to the image file(s). \"\"\" return self . _x y () -> ElementClass property Gets the class of the dataset element. Source code in revelio/dataset/element.py 51 52 53 54 55 56 @property def y ( self ) -> ElementClass : \"\"\" Gets the class of the dataset element. \"\"\" return self . _y ElementClass Bases: Enum The class of a dataset element, which can be either bona fide or morphed. Source code in revelio/dataset/element.py 10 11 12 13 14 15 16 class ElementClass ( Enum ): \"\"\" The class of a dataset element, which can be either bona fide or morphed. \"\"\" BONA_FIDE = 0.0 MORPHED = 1.0 ElementImage An image that is part of a dataset element. An image is represented with a Numpy array with shape (height, width, channels) and dtype uint8 or float32. The channels are ordered as BGR, following the OpenCV convention. Attributes: Name Type Description path Path The path to the image file. image Image The image. landmarks Optional [ np . ndarray ] The facial landmarks of the image (if present). features dict [ str , np . ndarray ] The features of the image produced by each feature extractor (if present). Source code in revelio/dataset/element.py 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 class ElementImage : \"\"\" An image that is part of a dataset element. An image is represented with a Numpy array with shape (height, width, channels) and dtype uint8 or float32. The channels are ordered as BGR, following the OpenCV convention. Attributes: path: The path to the image file. image: The image. landmarks: The facial landmarks of the image (if present). features: The features of the image produced by each feature extractor (if present). \"\"\" _path : Path _image : Image _landmarks : Optional [ np . ndarray ] _features : dict [ str , np . ndarray ] def __init__ ( self , path : Path , image : Image , landmarks : Optional [ np . ndarray ] = None , features : Optional [ dict [ str , np . ndarray ]] = None , ) -> None : \"\"\" Creates a new image of a dataset element. Args: path: The path to the image file. image: The image. landmarks: The facial landmarks of the image (if present). features: The features of the image produced by each feature extractor (if present). \"\"\" self . _path = path self . _image = image self . _landmarks = landmarks self . _features = features or {} @property def path ( self ) -> Path : \"\"\" Gets the path to the image file. \"\"\" return self . _path @property def image ( self ) -> Image : \"\"\" Gets the image. \"\"\" return self . _image @property def landmarks ( self ) -> Optional [ np . ndarray ]: \"\"\" Gets the facial landmarks of the image (if present). \"\"\" return self . _landmarks @property def features ( self ) -> dict [ str , np . ndarray ]: \"\"\" Gets the features of the image produced by each feature extractor (if present). \"\"\" return self . _features def __repr__ ( self ) -> str : return f \"ElementImage(path= { self . _path } )\" __init__ ( path : Path , image : Image , landmarks : Optional [ np . ndarray ] = None , features : Optional [ dict [ str , np . ndarray ]] = None ) -> None Creates a new image of a dataset element. Parameters: Name Type Description Default path Path The path to the image file. required image Image The image. required landmarks Optional [ np . ndarray ] The facial landmarks of the image (if present). None features Optional [ dict [ str , np . ndarray ]] The features of the image produced by each feature extractor (if present). None Source code in revelio/dataset/element.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 def __init__ ( self , path : Path , image : Image , landmarks : Optional [ np . ndarray ] = None , features : Optional [ dict [ str , np . ndarray ]] = None , ) -> None : \"\"\" Creates a new image of a dataset element. Args: path: The path to the image file. image: The image. landmarks: The facial landmarks of the image (if present). features: The features of the image produced by each feature extractor (if present). \"\"\" self . _path = path self . _image = image self . _landmarks = landmarks self . _features = features or {} features () -> dict [ str , np . ndarray ] property Gets the features of the image produced by each feature extractor (if present). Source code in revelio/dataset/element.py 139 140 141 142 143 144 @property def features ( self ) -> dict [ str , np . ndarray ]: \"\"\" Gets the features of the image produced by each feature extractor (if present). \"\"\" return self . _features image () -> Image property Gets the image. Source code in revelio/dataset/element.py 125 126 127 128 129 130 @property def image ( self ) -> Image : \"\"\" Gets the image. \"\"\" return self . _image landmarks () -> Optional [ np . ndarray ] property Gets the facial landmarks of the image (if present). Source code in revelio/dataset/element.py 132 133 134 135 136 137 @property def landmarks ( self ) -> Optional [ np . ndarray ]: \"\"\" Gets the facial landmarks of the image (if present). \"\"\" return self . _landmarks path () -> Path property Gets the path to the image file. Source code in revelio/dataset/element.py 118 119 120 121 122 123 @property def path ( self ) -> Path : \"\"\" Gets the path to the image file. \"\"\" return self . _path","title":"element"},{"location":"reference/revelio/dataset/element/#revelio.dataset.element.DatasetElement","text":"An element of the dataset. Attributes: Name Type Description x tuple [ ElementImage , ...] The image(s) of the dataset element. y ElementClass The class of the dataset element. original_dataset str The name of the original dataset from which the element was taken. It is equal to the dataset name specified in the configuration file. dataset_root_path Path The path to the root directory of the dataset. Source code in revelio/dataset/element.py 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 class DatasetElement : \"\"\" An element of the dataset. Attributes: x: The image(s) of the dataset element. y: The class of the dataset element. original_dataset: The name of the original dataset from which the element was taken. It is equal to the dataset name specified in the configuration file. dataset_root_path: The path to the root directory of the dataset. \"\"\" _dataset_root_path : Path _original_dataset : str _x : tuple [ ElementImage , ... ] _y : ElementClass def __init__ ( self , x : tuple [ ElementImage , ... ], y : ElementClass , * , dataset_root_path : Path , original_dataset : str , ) -> None : \"\"\" Creates a new dataset element. Args: x: The image(s) of the dataset element. y: The class of the dataset element. dataset_root_path: The path to the root directory of the dataset. original_dataset: The name of the original dataset from which the element was taken. \"\"\" self . _x = x self . _y = y self . _dataset_root_path = dataset_root_path self . _original_dataset = original_dataset @property def dataset_root_path ( self ) -> Path : \"\"\" Gets the path to the root directory of the dataset. \"\"\" return self . _dataset_root_path @property def original_dataset ( self ) -> str : \"\"\" Gets the name of the original dataset from which the element was taken. \"\"\" return self . _original_dataset @property def x ( self ) -> tuple [ ElementImage , ... ]: \"\"\" Gets the image(s) of the dataset element. \"\"\" return self . _x @property def y ( self ) -> ElementClass : \"\"\" Gets the class of the dataset element. \"\"\" return self . _y def __repr__ ( self ) -> str : return f \"DatasetElement(x= { self . x } , y= { self . y } )\"","title":"DatasetElement"},{"location":"reference/revelio/dataset/element/#revelio.dataset.element.DatasetElement.__init__","text":"Creates a new dataset element. Parameters: Name Type Description Default x tuple [ ElementImage , ...] The image(s) of the dataset element. required y ElementClass The class of the dataset element. required dataset_root_path Path The path to the root directory of the dataset. required original_dataset str The name of the original dataset from which the element was taken. required Source code in revelio/dataset/element.py 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 def __init__ ( self , x : tuple [ ElementImage , ... ], y : ElementClass , * , dataset_root_path : Path , original_dataset : str , ) -> None : \"\"\" Creates a new dataset element. Args: x: The image(s) of the dataset element. y: The class of the dataset element. dataset_root_path: The path to the root directory of the dataset. original_dataset: The name of the original dataset from which the element was taken. \"\"\" self . _x = x self . _y = y self . _dataset_root_path = dataset_root_path self . _original_dataset = original_dataset","title":"__init__()"},{"location":"reference/revelio/dataset/element/#revelio.dataset.element.DatasetElement.dataset_root_path","text":"Gets the path to the root directory of the dataset. Source code in revelio/dataset/element.py 191 192 193 194 195 196 @property def dataset_root_path ( self ) -> Path : \"\"\" Gets the path to the root directory of the dataset. \"\"\" return self . _dataset_root_path","title":"dataset_root_path()"},{"location":"reference/revelio/dataset/element/#revelio.dataset.element.DatasetElement.original_dataset","text":"Gets the name of the original dataset from which the element was taken. Source code in revelio/dataset/element.py 198 199 200 201 202 203 @property def original_dataset ( self ) -> str : \"\"\" Gets the name of the original dataset from which the element was taken. \"\"\" return self . _original_dataset","title":"original_dataset()"},{"location":"reference/revelio/dataset/element/#revelio.dataset.element.DatasetElement.x","text":"Gets the image(s) of the dataset element. Source code in revelio/dataset/element.py 205 206 207 208 209 210 @property def x ( self ) -> tuple [ ElementImage , ... ]: \"\"\" Gets the image(s) of the dataset element. \"\"\" return self . _x","title":"x()"},{"location":"reference/revelio/dataset/element/#revelio.dataset.element.DatasetElement.y","text":"Gets the class of the dataset element. Source code in revelio/dataset/element.py 212 213 214 215 216 217 @property def y ( self ) -> ElementClass : \"\"\" Gets the class of the dataset element. \"\"\" return self . _y","title":"y()"},{"location":"reference/revelio/dataset/element/#revelio.dataset.element.DatasetElementDescriptor","text":"A descriptor of a dataset element before it is loaded into memory. Attributes: Name Type Description x tuple [ Path , ...] The path to the image file(s). y ElementClass The class of the dataset element. Source code in revelio/dataset/element.py 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 class DatasetElementDescriptor : \"\"\" A descriptor of a dataset element before it is loaded into memory. Attributes: x: The path to the image file(s). y: The class of the dataset element. \"\"\" _x : tuple [ Path , ... ] _y : ElementClass _root_path : Path _dataset_name : str def __init__ ( self , x : tuple [ Path , ... ], y : ElementClass ) -> None : \"\"\" Creates a new dataset element descriptor. Args: x: The path to the image file(s). y: The class of the dataset element. \"\"\" self . _x = x self . _y = y @property def x ( self ) -> tuple [ Path , ... ]: \"\"\" Gets the path to the image file(s). \"\"\" return self . _x @property def y ( self ) -> ElementClass : \"\"\" Gets the class of the dataset element. \"\"\" return self . _y def __repr__ ( self ) -> str : return f \"DatasetElementDescriptor(x= { self . x } , y= { self . y } )\" def __eq__ ( self , other : Any ) -> bool : if not isinstance ( other , DatasetElementDescriptor ): return NotImplemented return ( self . x == other . x and self . y == other . y and self . _root_path == other . _root_path and self . _dataset_name == other . _dataset_name ) def __hash__ ( self ) -> int : return hash (( self . x , self . y , self . _root_path , self . _dataset_name ))","title":"DatasetElementDescriptor"},{"location":"reference/revelio/dataset/element/#revelio.dataset.element.DatasetElementDescriptor.__init__","text":"Creates a new dataset element descriptor. Parameters: Name Type Description Default x tuple [ Path , ...] The path to the image file(s). required y ElementClass The class of the dataset element. required Source code in revelio/dataset/element.py 33 34 35 36 37 38 39 40 41 42 def __init__ ( self , x : tuple [ Path , ... ], y : ElementClass ) -> None : \"\"\" Creates a new dataset element descriptor. Args: x: The path to the image file(s). y: The class of the dataset element. \"\"\" self . _x = x self . _y = y","title":"__init__()"},{"location":"reference/revelio/dataset/element/#revelio.dataset.element.DatasetElementDescriptor.x","text":"Gets the path to the image file(s). Source code in revelio/dataset/element.py 44 45 46 47 48 49 @property def x ( self ) -> tuple [ Path , ... ]: \"\"\" Gets the path to the image file(s). \"\"\" return self . _x","title":"x()"},{"location":"reference/revelio/dataset/element/#revelio.dataset.element.DatasetElementDescriptor.y","text":"Gets the class of the dataset element. Source code in revelio/dataset/element.py 51 52 53 54 55 56 @property def y ( self ) -> ElementClass : \"\"\" Gets the class of the dataset element. \"\"\" return self . _y","title":"y()"},{"location":"reference/revelio/dataset/element/#revelio.dataset.element.ElementClass","text":"Bases: Enum The class of a dataset element, which can be either bona fide or morphed. Source code in revelio/dataset/element.py 10 11 12 13 14 15 16 class ElementClass ( Enum ): \"\"\" The class of a dataset element, which can be either bona fide or morphed. \"\"\" BONA_FIDE = 0.0 MORPHED = 1.0","title":"ElementClass"},{"location":"reference/revelio/dataset/element/#revelio.dataset.element.ElementImage","text":"An image that is part of a dataset element. An image is represented with a Numpy array with shape (height, width, channels) and dtype uint8 or float32. The channels are ordered as BGR, following the OpenCV convention. Attributes: Name Type Description path Path The path to the image file. image Image The image. landmarks Optional [ np . ndarray ] The facial landmarks of the image (if present). features dict [ str , np . ndarray ] The features of the image produced by each feature extractor (if present). Source code in revelio/dataset/element.py 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 class ElementImage : \"\"\" An image that is part of a dataset element. An image is represented with a Numpy array with shape (height, width, channels) and dtype uint8 or float32. The channels are ordered as BGR, following the OpenCV convention. Attributes: path: The path to the image file. image: The image. landmarks: The facial landmarks of the image (if present). features: The features of the image produced by each feature extractor (if present). \"\"\" _path : Path _image : Image _landmarks : Optional [ np . ndarray ] _features : dict [ str , np . ndarray ] def __init__ ( self , path : Path , image : Image , landmarks : Optional [ np . ndarray ] = None , features : Optional [ dict [ str , np . ndarray ]] = None , ) -> None : \"\"\" Creates a new image of a dataset element. Args: path: The path to the image file. image: The image. landmarks: The facial landmarks of the image (if present). features: The features of the image produced by each feature extractor (if present). \"\"\" self . _path = path self . _image = image self . _landmarks = landmarks self . _features = features or {} @property def path ( self ) -> Path : \"\"\" Gets the path to the image file. \"\"\" return self . _path @property def image ( self ) -> Image : \"\"\" Gets the image. \"\"\" return self . _image @property def landmarks ( self ) -> Optional [ np . ndarray ]: \"\"\" Gets the facial landmarks of the image (if present). \"\"\" return self . _landmarks @property def features ( self ) -> dict [ str , np . ndarray ]: \"\"\" Gets the features of the image produced by each feature extractor (if present). \"\"\" return self . _features def __repr__ ( self ) -> str : return f \"ElementImage(path= { self . _path } )\"","title":"ElementImage"},{"location":"reference/revelio/dataset/element/#revelio.dataset.element.ElementImage.__init__","text":"Creates a new image of a dataset element. Parameters: Name Type Description Default path Path The path to the image file. required image Image The image. required landmarks Optional [ np . ndarray ] The facial landmarks of the image (if present). None features Optional [ dict [ str , np . ndarray ]] The features of the image produced by each feature extractor (if present). None Source code in revelio/dataset/element.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 def __init__ ( self , path : Path , image : Image , landmarks : Optional [ np . ndarray ] = None , features : Optional [ dict [ str , np . ndarray ]] = None , ) -> None : \"\"\" Creates a new image of a dataset element. Args: path: The path to the image file. image: The image. landmarks: The facial landmarks of the image (if present). features: The features of the image produced by each feature extractor (if present). \"\"\" self . _path = path self . _image = image self . _landmarks = landmarks self . _features = features or {}","title":"__init__()"},{"location":"reference/revelio/dataset/element/#revelio.dataset.element.ElementImage.features","text":"Gets the features of the image produced by each feature extractor (if present). Source code in revelio/dataset/element.py 139 140 141 142 143 144 @property def features ( self ) -> dict [ str , np . ndarray ]: \"\"\" Gets the features of the image produced by each feature extractor (if present). \"\"\" return self . _features","title":"features()"},{"location":"reference/revelio/dataset/element/#revelio.dataset.element.ElementImage.image","text":"Gets the image. Source code in revelio/dataset/element.py 125 126 127 128 129 130 @property def image ( self ) -> Image : \"\"\" Gets the image. \"\"\" return self . _image","title":"image()"},{"location":"reference/revelio/dataset/element/#revelio.dataset.element.ElementImage.landmarks","text":"Gets the facial landmarks of the image (if present). Source code in revelio/dataset/element.py 132 133 134 135 136 137 @property def landmarks ( self ) -> Optional [ np . ndarray ]: \"\"\" Gets the facial landmarks of the image (if present). \"\"\" return self . _landmarks","title":"landmarks()"},{"location":"reference/revelio/dataset/element/#revelio.dataset.element.ElementImage.path","text":"Gets the path to the image file. Source code in revelio/dataset/element.py 118 119 120 121 122 123 @property def path ( self ) -> Path : \"\"\" Gets the path to the image file. \"\"\" return self . _path","title":"path()"},{"location":"reference/revelio/dataset/loaders/","text":"","title":"loaders"},{"location":"reference/revelio/dataset/loaders/loader/","text":"DatasetLoader Bases: Registrable A dataset loader is responsible for loading a dataset from a given path. The configuration file specifies the dataset loader to use on the path given by the user, and its job is to correctly load the dataset from that path. To load a dataset element, the loader must return a list of descriptors, each containing the path of each image and the class of the element. In case of D-MAD, the convention that must be followed is that the first element in the tuple must be the probe image, and the second element must be the live capture image. To guarantee reproducibility of results, it is important that the list returned by the loader is the same for the same path, and its order must be deterministic. Also, please note that the glob functions in Python are not guaranteed to return the files in a deterministic order, so you should sort the list of files before returning it. Source code in revelio/dataset/loaders/loader.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 class DatasetLoader ( Registrable ): \"\"\" A dataset loader is responsible for loading a dataset from a given path. The configuration file specifies the dataset loader to use on the path given by the user, and its job is to correctly load the dataset from that path. To load a dataset element, the loader must return a list of descriptors, each containing the path of each image and the class of the element. In case of D-MAD, the convention that must be followed is that the first element in the tuple must be the probe image, and the second element must be the live capture image. To guarantee reproducibility of results, it is important that the list returned by the loader is the same for the same path, and its order must be deterministic. Also, please note that the glob functions in Python are not guaranteed to return the files in a deterministic order, so you should sort the list of files before returning it. \"\"\" suffix = \"Loader\" @abstractmethod def load ( self , path : Path ) -> list [ DatasetElementDescriptor ]: \"\"\" Loads a dataset from a given path. Args: path: The path to the dataset. Returns: A list of descriptors, each containing the path of each image and the class of the element. \"\"\" raise NotImplementedError # pragma: no cover load ( path : Path ) -> list [ DatasetElementDescriptor ] abstractmethod Loads a dataset from a given path. Parameters: Name Type Description Default path Path The path to the dataset. required Returns: Type Description list [ DatasetElementDescriptor ] A list of descriptors, each containing the path of each image and the list [ DatasetElementDescriptor ] class of the element. Source code in revelio/dataset/loaders/loader.py 32 33 34 35 36 37 38 39 40 41 42 43 44 @abstractmethod def load ( self , path : Path ) -> list [ DatasetElementDescriptor ]: \"\"\" Loads a dataset from a given path. Args: path: The path to the dataset. Returns: A list of descriptors, each containing the path of each image and the class of the element. \"\"\" raise NotImplementedError # pragma: no cover","title":"loader"},{"location":"reference/revelio/dataset/loaders/loader/#revelio.dataset.loaders.loader.DatasetLoader","text":"Bases: Registrable A dataset loader is responsible for loading a dataset from a given path. The configuration file specifies the dataset loader to use on the path given by the user, and its job is to correctly load the dataset from that path. To load a dataset element, the loader must return a list of descriptors, each containing the path of each image and the class of the element. In case of D-MAD, the convention that must be followed is that the first element in the tuple must be the probe image, and the second element must be the live capture image. To guarantee reproducibility of results, it is important that the list returned by the loader is the same for the same path, and its order must be deterministic. Also, please note that the glob functions in Python are not guaranteed to return the files in a deterministic order, so you should sort the list of files before returning it. Source code in revelio/dataset/loaders/loader.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 class DatasetLoader ( Registrable ): \"\"\" A dataset loader is responsible for loading a dataset from a given path. The configuration file specifies the dataset loader to use on the path given by the user, and its job is to correctly load the dataset from that path. To load a dataset element, the loader must return a list of descriptors, each containing the path of each image and the class of the element. In case of D-MAD, the convention that must be followed is that the first element in the tuple must be the probe image, and the second element must be the live capture image. To guarantee reproducibility of results, it is important that the list returned by the loader is the same for the same path, and its order must be deterministic. Also, please note that the glob functions in Python are not guaranteed to return the files in a deterministic order, so you should sort the list of files before returning it. \"\"\" suffix = \"Loader\" @abstractmethod def load ( self , path : Path ) -> list [ DatasetElementDescriptor ]: \"\"\" Loads a dataset from a given path. Args: path: The path to the dataset. Returns: A list of descriptors, each containing the path of each image and the class of the element. \"\"\" raise NotImplementedError # pragma: no cover","title":"DatasetLoader"},{"location":"reference/revelio/dataset/loaders/loader/#revelio.dataset.loaders.loader.DatasetLoader.load","text":"Loads a dataset from a given path. Parameters: Name Type Description Default path Path The path to the dataset. required Returns: Type Description list [ DatasetElementDescriptor ] A list of descriptors, each containing the path of each image and the list [ DatasetElementDescriptor ] class of the element. Source code in revelio/dataset/loaders/loader.py 32 33 34 35 36 37 38 39 40 41 42 43 44 @abstractmethod def load ( self , path : Path ) -> list [ DatasetElementDescriptor ]: \"\"\" Loads a dataset from a given path. Args: path: The path to the dataset. Returns: A list of descriptors, each containing the path of each image and the class of the element. \"\"\" raise NotImplementedError # pragma: no cover","title":"load()"},{"location":"reference/revelio/dataset/loaders/loaders/","text":"","title":"loaders"},{"location":"reference/revelio/face_detection/","text":"","title":"face_detection"},{"location":"reference/revelio/face_detection/detector/","text":"FaceDetector Bases: Registrable A face detector is responsible for detecting faces in the dataset images. It is also responsible for cropping the images to only contain the face, and for detecting the facial landmarks (if the algorithm supports it). A face detector must implement the process_element method, which takes an image and returns the bounding box of the face and the facial landmarks, if the algorithm supports such extraction, or else None. The bounding box is a tuple of 4 integers, representing the top-left and bottom-right coordinates of the bounding box, while the landmarks is a NumPy array of variable length, where each row represents a landmark and each column represents the x and y integer coordinates of the landmark, with origin at the top-left corner of the image. If no landmarks can be computed from the image (e.g. because the chosen face detection algorithm does not support landmark extraction), the returned value for the landmarks should be None. If the process_element method raises an exception, the dataset element will be skipped and the exception will be logged. The process method is responsible for loading the bounding box and landmarks from the disk, if they have been already computed, or else calling process_element and saving the results. The user should not override this method, but instead implement process_element . Source code in revelio/face_detection/detector.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 class FaceDetector ( Registrable ): \"\"\" A face detector is responsible for detecting faces in the dataset images. It is also responsible for cropping the images to only contain the face, and for detecting the facial landmarks (if the algorithm supports it). A face detector must implement the `process_element` method, which takes an image and returns the bounding box of the face and the facial landmarks, if the algorithm supports such extraction, or else None. The bounding box is a tuple of 4 integers, representing the top-left and bottom-right coordinates of the bounding box, while the landmarks is a NumPy array of variable length, where each row represents a landmark and each column represents the x and y integer coordinates of the landmark, with origin at the top-left corner of the image. If no landmarks can be computed from the image (e.g. because the chosen face detection algorithm does not support landmark extraction), the returned value for the landmarks should be None. If the `process_element` method raises an exception, the dataset element will be skipped and the exception will be logged. The `process` method is responsible for loading the bounding box and landmarks from the disk, if they have been already computed, or else calling `process_element` and saving the results. The user should not override this method, but instead implement `process_element`. \"\"\" def __init__ ( self , * , _config : Config ) -> None : self . _config = _config def _get_meta_path ( self , elem : DatasetElement , x_idx : int ) -> Path : output_path = Path ( self . _config . face_detection . output_path ) algorithm_name = type ( self ) . __name__ . lower () relative_img_path = elem . x [ x_idx ] . path . relative_to ( elem . dataset_root_path ) return ( output_path / algorithm_name / elem . original_dataset / relative_img_path . parent / f \" { relative_img_path . stem } .meta.npz\" ) @abstractmethod def process_element ( self , elem : Image ) -> tuple [ BoundingBox , Optional [ Landmarks ]]: \"\"\" Processes a single image and returns the bounding box of the face and the facial landmarks, if the algorithm supports such extraction, or else None. The bounding box is a tuple of 4 integers, representing the top-left and bottom-right coordinates of the bounding box, while the landmarks is a NumPy array of variable length, where each row represents a landmark and each column represents the x and y integer coordinates of the landmark, with origin at the top-left corner of the image. If no landmarks can be computed from the image (e.g. because the chosen face detection algorithm does not support landmark extraction), the returned value for the landmarks should be None. If the `process_element` method raises an exception, the dataset element will be skipped and the exception will be logged. Args: elem: The image to process. Returns: A tuple containing the bounding box (required) and the facial landmarks (optional). \"\"\" raise NotImplementedError # pragma: no cover def process ( self , elem : DatasetElement ) -> tuple [ DatasetElement , bool ]: \"\"\" Processes a dataset element and returns an element with the same data, but with each image cropped to only contain the face. Also, if the algorithm supports it, the facial landmarks are extracted and saved for each image of the element. This method saves the bounding box and the facial landmarks to the disk, so that they can be loaded later without having to recompute them. This method should not be overridden by the user, but instead the `process_element` method should be implemented. Args: elem: The dataset element to process. Returns: A tuple containing the processed dataset element and a boolean indicating whether the face detection was loaded from cache. \"\"\" new_xs = [] cached = True for i , x in enumerate ( elem . x ): meta_path = self . _get_meta_path ( elem , i ) if meta_path . is_file (): try : meta = np . load ( meta_path ) except ValueError as e : raise RuntimeError ( f \"Failed to load meta file: { meta_path } \" ) from e landmarks = meta [ \"landmarks\" ] if \"landmarks\" in meta else None if \"bb\" in meta : # We have the bounding boxes, skip loading a new image # and instead crop the one we already have x1 , y1 , x2 , y2 = meta [ \"bb\" ] image = x . image [ y1 : y2 , x1 : x2 ] new_x = ElementImage ( path = x . path , image = image , landmarks = landmarks , ) new_xs . append ( new_x ) else : raise ValueError ( f \"No bounding box found in { meta_path } \" ) else : cached = False try : bb , landmarks = self . process_element ( x . image ) except Exception as e : raise RuntimeError ( f \"Failed to process { x . path } : { e } \" ) from e # Make sure that the bounding box is always inside the image clipped_bb = ( max ( 0 , bb [ 0 ]), max ( 0 , bb [ 1 ]), min ( x . image . shape [ 1 ], bb [ 2 ]), min ( x . image . shape [ 0 ], bb [ 3 ]), ) x1 , y1 , x2 , y2 = clipped_bb new_x = ElementImage ( path = x . path , image = x . image [ y1 : y2 , x1 : x2 ], landmarks = landmarks , ) # Create the meta file meta_path . parent . mkdir ( parents = True , exist_ok = True ) if landmarks is not None : np . savez_compressed ( meta_path , bb = clipped_bb , landmarks = landmarks ) else : np . savez_compressed ( meta_path , bb = clipped_bb ) new_xs . append ( new_x ) return ( DatasetElement ( dataset_root_path = elem . dataset_root_path , original_dataset = elem . original_dataset , x = tuple ( new_xs ), y = elem . y , ), cached , ) process ( elem : DatasetElement ) -> tuple [ DatasetElement , bool ] Processes a dataset element and returns an element with the same data, but with each image cropped to only contain the face. Also, if the algorithm supports it, the facial landmarks are extracted and saved for each image of the element. This method saves the bounding box and the facial landmarks to the disk, so that they can be loaded later without having to recompute them. This method should not be overridden by the user, but instead the process_element method should be implemented. Parameters: Name Type Description Default elem DatasetElement The dataset element to process. required Returns: Type Description DatasetElement A tuple containing the processed dataset element and a boolean indicating bool whether the face detection was loaded from cache. Source code in revelio/face_detection/detector.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 def process ( self , elem : DatasetElement ) -> tuple [ DatasetElement , bool ]: \"\"\" Processes a dataset element and returns an element with the same data, but with each image cropped to only contain the face. Also, if the algorithm supports it, the facial landmarks are extracted and saved for each image of the element. This method saves the bounding box and the facial landmarks to the disk, so that they can be loaded later without having to recompute them. This method should not be overridden by the user, but instead the `process_element` method should be implemented. Args: elem: The dataset element to process. Returns: A tuple containing the processed dataset element and a boolean indicating whether the face detection was loaded from cache. \"\"\" new_xs = [] cached = True for i , x in enumerate ( elem . x ): meta_path = self . _get_meta_path ( elem , i ) if meta_path . is_file (): try : meta = np . load ( meta_path ) except ValueError as e : raise RuntimeError ( f \"Failed to load meta file: { meta_path } \" ) from e landmarks = meta [ \"landmarks\" ] if \"landmarks\" in meta else None if \"bb\" in meta : # We have the bounding boxes, skip loading a new image # and instead crop the one we already have x1 , y1 , x2 , y2 = meta [ \"bb\" ] image = x . image [ y1 : y2 , x1 : x2 ] new_x = ElementImage ( path = x . path , image = image , landmarks = landmarks , ) new_xs . append ( new_x ) else : raise ValueError ( f \"No bounding box found in { meta_path } \" ) else : cached = False try : bb , landmarks = self . process_element ( x . image ) except Exception as e : raise RuntimeError ( f \"Failed to process { x . path } : { e } \" ) from e # Make sure that the bounding box is always inside the image clipped_bb = ( max ( 0 , bb [ 0 ]), max ( 0 , bb [ 1 ]), min ( x . image . shape [ 1 ], bb [ 2 ]), min ( x . image . shape [ 0 ], bb [ 3 ]), ) x1 , y1 , x2 , y2 = clipped_bb new_x = ElementImage ( path = x . path , image = x . image [ y1 : y2 , x1 : x2 ], landmarks = landmarks , ) # Create the meta file meta_path . parent . mkdir ( parents = True , exist_ok = True ) if landmarks is not None : np . savez_compressed ( meta_path , bb = clipped_bb , landmarks = landmarks ) else : np . savez_compressed ( meta_path , bb = clipped_bb ) new_xs . append ( new_x ) return ( DatasetElement ( dataset_root_path = elem . dataset_root_path , original_dataset = elem . original_dataset , x = tuple ( new_xs ), y = elem . y , ), cached , ) process_element ( elem : Image ) -> tuple [ BoundingBox , Optional [ Landmarks ]] abstractmethod Processes a single image and returns the bounding box of the face and the facial landmarks, if the algorithm supports such extraction, or else None. The bounding box is a tuple of 4 integers, representing the top-left and bottom-right coordinates of the bounding box, while the landmarks is a NumPy array of variable length, where each row represents a landmark and each column represents the x and y integer coordinates of the landmark, with origin at the top-left corner of the image. If no landmarks can be computed from the image (e.g. because the chosen face detection algorithm does not support landmark extraction), the returned value for the landmarks should be None. If the process_element method raises an exception, the dataset element will be skipped and the exception will be logged. Parameters: Name Type Description Default elem Image The image to process. required Returns: Type Description BoundingBox A tuple containing the bounding box (required) and the facial landmarks Optional [ Landmarks ] (optional). Source code in revelio/face_detection/detector.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 @abstractmethod def process_element ( self , elem : Image ) -> tuple [ BoundingBox , Optional [ Landmarks ]]: \"\"\" Processes a single image and returns the bounding box of the face and the facial landmarks, if the algorithm supports such extraction, or else None. The bounding box is a tuple of 4 integers, representing the top-left and bottom-right coordinates of the bounding box, while the landmarks is a NumPy array of variable length, where each row represents a landmark and each column represents the x and y integer coordinates of the landmark, with origin at the top-left corner of the image. If no landmarks can be computed from the image (e.g. because the chosen face detection algorithm does not support landmark extraction), the returned value for the landmarks should be None. If the `process_element` method raises an exception, the dataset element will be skipped and the exception will be logged. Args: elem: The image to process. Returns: A tuple containing the bounding box (required) and the facial landmarks (optional). \"\"\" raise NotImplementedError # pragma: no cover","title":"detector"},{"location":"reference/revelio/face_detection/detector/#revelio.face_detection.detector.FaceDetector","text":"Bases: Registrable A face detector is responsible for detecting faces in the dataset images. It is also responsible for cropping the images to only contain the face, and for detecting the facial landmarks (if the algorithm supports it). A face detector must implement the process_element method, which takes an image and returns the bounding box of the face and the facial landmarks, if the algorithm supports such extraction, or else None. The bounding box is a tuple of 4 integers, representing the top-left and bottom-right coordinates of the bounding box, while the landmarks is a NumPy array of variable length, where each row represents a landmark and each column represents the x and y integer coordinates of the landmark, with origin at the top-left corner of the image. If no landmarks can be computed from the image (e.g. because the chosen face detection algorithm does not support landmark extraction), the returned value for the landmarks should be None. If the process_element method raises an exception, the dataset element will be skipped and the exception will be logged. The process method is responsible for loading the bounding box and landmarks from the disk, if they have been already computed, or else calling process_element and saving the results. The user should not override this method, but instead implement process_element . Source code in revelio/face_detection/detector.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 class FaceDetector ( Registrable ): \"\"\" A face detector is responsible for detecting faces in the dataset images. It is also responsible for cropping the images to only contain the face, and for detecting the facial landmarks (if the algorithm supports it). A face detector must implement the `process_element` method, which takes an image and returns the bounding box of the face and the facial landmarks, if the algorithm supports such extraction, or else None. The bounding box is a tuple of 4 integers, representing the top-left and bottom-right coordinates of the bounding box, while the landmarks is a NumPy array of variable length, where each row represents a landmark and each column represents the x and y integer coordinates of the landmark, with origin at the top-left corner of the image. If no landmarks can be computed from the image (e.g. because the chosen face detection algorithm does not support landmark extraction), the returned value for the landmarks should be None. If the `process_element` method raises an exception, the dataset element will be skipped and the exception will be logged. The `process` method is responsible for loading the bounding box and landmarks from the disk, if they have been already computed, or else calling `process_element` and saving the results. The user should not override this method, but instead implement `process_element`. \"\"\" def __init__ ( self , * , _config : Config ) -> None : self . _config = _config def _get_meta_path ( self , elem : DatasetElement , x_idx : int ) -> Path : output_path = Path ( self . _config . face_detection . output_path ) algorithm_name = type ( self ) . __name__ . lower () relative_img_path = elem . x [ x_idx ] . path . relative_to ( elem . dataset_root_path ) return ( output_path / algorithm_name / elem . original_dataset / relative_img_path . parent / f \" { relative_img_path . stem } .meta.npz\" ) @abstractmethod def process_element ( self , elem : Image ) -> tuple [ BoundingBox , Optional [ Landmarks ]]: \"\"\" Processes a single image and returns the bounding box of the face and the facial landmarks, if the algorithm supports such extraction, or else None. The bounding box is a tuple of 4 integers, representing the top-left and bottom-right coordinates of the bounding box, while the landmarks is a NumPy array of variable length, where each row represents a landmark and each column represents the x and y integer coordinates of the landmark, with origin at the top-left corner of the image. If no landmarks can be computed from the image (e.g. because the chosen face detection algorithm does not support landmark extraction), the returned value for the landmarks should be None. If the `process_element` method raises an exception, the dataset element will be skipped and the exception will be logged. Args: elem: The image to process. Returns: A tuple containing the bounding box (required) and the facial landmarks (optional). \"\"\" raise NotImplementedError # pragma: no cover def process ( self , elem : DatasetElement ) -> tuple [ DatasetElement , bool ]: \"\"\" Processes a dataset element and returns an element with the same data, but with each image cropped to only contain the face. Also, if the algorithm supports it, the facial landmarks are extracted and saved for each image of the element. This method saves the bounding box and the facial landmarks to the disk, so that they can be loaded later without having to recompute them. This method should not be overridden by the user, but instead the `process_element` method should be implemented. Args: elem: The dataset element to process. Returns: A tuple containing the processed dataset element and a boolean indicating whether the face detection was loaded from cache. \"\"\" new_xs = [] cached = True for i , x in enumerate ( elem . x ): meta_path = self . _get_meta_path ( elem , i ) if meta_path . is_file (): try : meta = np . load ( meta_path ) except ValueError as e : raise RuntimeError ( f \"Failed to load meta file: { meta_path } \" ) from e landmarks = meta [ \"landmarks\" ] if \"landmarks\" in meta else None if \"bb\" in meta : # We have the bounding boxes, skip loading a new image # and instead crop the one we already have x1 , y1 , x2 , y2 = meta [ \"bb\" ] image = x . image [ y1 : y2 , x1 : x2 ] new_x = ElementImage ( path = x . path , image = image , landmarks = landmarks , ) new_xs . append ( new_x ) else : raise ValueError ( f \"No bounding box found in { meta_path } \" ) else : cached = False try : bb , landmarks = self . process_element ( x . image ) except Exception as e : raise RuntimeError ( f \"Failed to process { x . path } : { e } \" ) from e # Make sure that the bounding box is always inside the image clipped_bb = ( max ( 0 , bb [ 0 ]), max ( 0 , bb [ 1 ]), min ( x . image . shape [ 1 ], bb [ 2 ]), min ( x . image . shape [ 0 ], bb [ 3 ]), ) x1 , y1 , x2 , y2 = clipped_bb new_x = ElementImage ( path = x . path , image = x . image [ y1 : y2 , x1 : x2 ], landmarks = landmarks , ) # Create the meta file meta_path . parent . mkdir ( parents = True , exist_ok = True ) if landmarks is not None : np . savez_compressed ( meta_path , bb = clipped_bb , landmarks = landmarks ) else : np . savez_compressed ( meta_path , bb = clipped_bb ) new_xs . append ( new_x ) return ( DatasetElement ( dataset_root_path = elem . dataset_root_path , original_dataset = elem . original_dataset , x = tuple ( new_xs ), y = elem . y , ), cached , )","title":"FaceDetector"},{"location":"reference/revelio/face_detection/detector/#revelio.face_detection.detector.FaceDetector.process","text":"Processes a dataset element and returns an element with the same data, but with each image cropped to only contain the face. Also, if the algorithm supports it, the facial landmarks are extracted and saved for each image of the element. This method saves the bounding box and the facial landmarks to the disk, so that they can be loaded later without having to recompute them. This method should not be overridden by the user, but instead the process_element method should be implemented. Parameters: Name Type Description Default elem DatasetElement The dataset element to process. required Returns: Type Description DatasetElement A tuple containing the processed dataset element and a boolean indicating bool whether the face detection was loaded from cache. Source code in revelio/face_detection/detector.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 def process ( self , elem : DatasetElement ) -> tuple [ DatasetElement , bool ]: \"\"\" Processes a dataset element and returns an element with the same data, but with each image cropped to only contain the face. Also, if the algorithm supports it, the facial landmarks are extracted and saved for each image of the element. This method saves the bounding box and the facial landmarks to the disk, so that they can be loaded later without having to recompute them. This method should not be overridden by the user, but instead the `process_element` method should be implemented. Args: elem: The dataset element to process. Returns: A tuple containing the processed dataset element and a boolean indicating whether the face detection was loaded from cache. \"\"\" new_xs = [] cached = True for i , x in enumerate ( elem . x ): meta_path = self . _get_meta_path ( elem , i ) if meta_path . is_file (): try : meta = np . load ( meta_path ) except ValueError as e : raise RuntimeError ( f \"Failed to load meta file: { meta_path } \" ) from e landmarks = meta [ \"landmarks\" ] if \"landmarks\" in meta else None if \"bb\" in meta : # We have the bounding boxes, skip loading a new image # and instead crop the one we already have x1 , y1 , x2 , y2 = meta [ \"bb\" ] image = x . image [ y1 : y2 , x1 : x2 ] new_x = ElementImage ( path = x . path , image = image , landmarks = landmarks , ) new_xs . append ( new_x ) else : raise ValueError ( f \"No bounding box found in { meta_path } \" ) else : cached = False try : bb , landmarks = self . process_element ( x . image ) except Exception as e : raise RuntimeError ( f \"Failed to process { x . path } : { e } \" ) from e # Make sure that the bounding box is always inside the image clipped_bb = ( max ( 0 , bb [ 0 ]), max ( 0 , bb [ 1 ]), min ( x . image . shape [ 1 ], bb [ 2 ]), min ( x . image . shape [ 0 ], bb [ 3 ]), ) x1 , y1 , x2 , y2 = clipped_bb new_x = ElementImage ( path = x . path , image = x . image [ y1 : y2 , x1 : x2 ], landmarks = landmarks , ) # Create the meta file meta_path . parent . mkdir ( parents = True , exist_ok = True ) if landmarks is not None : np . savez_compressed ( meta_path , bb = clipped_bb , landmarks = landmarks ) else : np . savez_compressed ( meta_path , bb = clipped_bb ) new_xs . append ( new_x ) return ( DatasetElement ( dataset_root_path = elem . dataset_root_path , original_dataset = elem . original_dataset , x = tuple ( new_xs ), y = elem . y , ), cached , )","title":"process()"},{"location":"reference/revelio/face_detection/detector/#revelio.face_detection.detector.FaceDetector.process_element","text":"Processes a single image and returns the bounding box of the face and the facial landmarks, if the algorithm supports such extraction, or else None. The bounding box is a tuple of 4 integers, representing the top-left and bottom-right coordinates of the bounding box, while the landmarks is a NumPy array of variable length, where each row represents a landmark and each column represents the x and y integer coordinates of the landmark, with origin at the top-left corner of the image. If no landmarks can be computed from the image (e.g. because the chosen face detection algorithm does not support landmark extraction), the returned value for the landmarks should be None. If the process_element method raises an exception, the dataset element will be skipped and the exception will be logged. Parameters: Name Type Description Default elem Image The image to process. required Returns: Type Description BoundingBox A tuple containing the bounding box (required) and the facial landmarks Optional [ Landmarks ] (optional). Source code in revelio/face_detection/detector.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 @abstractmethod def process_element ( self , elem : Image ) -> tuple [ BoundingBox , Optional [ Landmarks ]]: \"\"\" Processes a single image and returns the bounding box of the face and the facial landmarks, if the algorithm supports such extraction, or else None. The bounding box is a tuple of 4 integers, representing the top-left and bottom-right coordinates of the bounding box, while the landmarks is a NumPy array of variable length, where each row represents a landmark and each column represents the x and y integer coordinates of the landmark, with origin at the top-left corner of the image. If no landmarks can be computed from the image (e.g. because the chosen face detection algorithm does not support landmark extraction), the returned value for the landmarks should be None. If the `process_element` method raises an exception, the dataset element will be skipped and the exception will be logged. Args: elem: The image to process. Returns: A tuple containing the bounding box (required) and the facial landmarks (optional). \"\"\" raise NotImplementedError # pragma: no cover","title":"process_element()"},{"location":"reference/revelio/face_detection/dlib_detector/","text":"","title":"dlib_detector"},{"location":"reference/revelio/face_detection/mtcnn_detector/","text":"","title":"mtcnn_detector"},{"location":"reference/revelio/face_detection/opencv_detector/","text":"","title":"opencv_detector"},{"location":"reference/revelio/feature_extraction/","text":"","title":"feature_extraction"},{"location":"reference/revelio/feature_extraction/extractor/","text":"FeatureExtractor Bases: Registrable A feature extractor is responsible for extracting various types of features from images. A feature extractor must implement the process_element method, which takes an image and returns the features extracted from it. The features are stored in a dictionary, where the key is the name of the feature extractor (without any \"extractor\" suffixes; e.g. the features produced by a Wavelets Extractor are accessible via the wavelets key) and the value contains the features extracted by the feature extractor. If the process_element method raises an exception, the dataset element will be skipped and the exception will be logged. The process method is responsible for loading the extracted features from the disk, if they have been already computed, or else calling process_element and saving the results. The user should not override this method, but instead implement process_element . Source code in revelio/feature_extraction/extractor.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 class FeatureExtractor ( Registrable ): \"\"\" A feature extractor is responsible for extracting various types of features from images. A feature extractor must implement the `process_element` method, which takes an image and returns the features extracted from it. The features are stored in a dictionary, where the key is the name of the feature extractor (without any \"extractor\" suffixes; e.g. the features produced by a Wavelets Extractor are accessible via the `wavelets` key) and the value contains the features extracted by the feature extractor. If the `process_element` method raises an exception, the dataset element will be skipped and the exception will be logged. The `process` method is responsible for loading the extracted features from the disk, if they have been already computed, or else calling `process_element` and saving the results. The user should not override this method, but instead implement `process_element`. \"\"\" def __init__ ( self , * , _config : Config ) -> None : self . _config = _config def _get_features_path ( self , elem : DatasetElement , x_idx : int ) -> Path : output_path = Path ( self . _config . feature_extraction . output_path ) algorithm_name = type ( self ) . __name__ . lower () relative_img_path = elem . x [ x_idx ] . path . relative_to ( elem . dataset_root_path ) return ( output_path / algorithm_name / elem . original_dataset / relative_img_path . parent / f \" { relative_img_path . stem } .features.npz\" ) @abstractmethod def process_element ( self , elem : ElementImage ) -> np . ndarray : \"\"\" Processes a single image and returns its features. If the `process_element` method raises an exception, the dataset element will be skipped and the exception will be logged. Args: elem: The image to process. Returns: A Numpy array containing the features extracted from the image. \"\"\" raise NotImplementedError # pragma: no cover def process ( self , elem : DatasetElement , force_online : bool = False ) -> tuple [ DatasetElement , bool ]: \"\"\" Processes a dataset element and returns an element with the same data, but with the extracted features added to the `features` dictionary of each image. This method saves the extracted features to the disk, so that they can be loaded later without having to recompute them. This method should not be overridden by the user, but instead the `process_element` method should be implemented. Args: elem: The dataset element to process. force_online: If True, the features are always computed online, even if they have been already computed and saved to the disk. Returns: A tuple containing the processed dataset element and a boolean indicating whether the feature extraction was loaded from cache. \"\"\" new_xs = [] cached = True algorithm_name = type ( self ) . __name__ . lower () algorithm_name = algorithm_name . replace ( \"extractor\" , \"\" ) for i , x in enumerate ( elem . x ): features_path = self . _get_features_path ( elem , i ) if features_path . is_file () and not force_online : try : features = np . load ( features_path )[ \"features\" ] except ValueError as e : raise RuntimeError ( f \"Failed to load features: { features_path } \" ) from e new_x = ElementImage ( path = x . path , image = x . image , features = { ** x . features , algorithm_name : features }, ) new_xs . append ( new_x ) else : cached = False try : features = self . process_element ( x ) except Exception as e : raise RuntimeError ( f \"Failed to process { x . path } : { e } \" ) from e if not force_online : # TODO: is it correct? # We don't need to save the features if we're forced to do it online # (that means we have one or more augmentation steps) features_path . parent . mkdir ( parents = True , exist_ok = True ) np . savez_compressed ( features_path , features = features ) new_x = ElementImage ( path = x . path , image = x . image , features = { ** x . features , algorithm_name : features }, ) new_xs . append ( new_x ) return ( DatasetElement ( dataset_root_path = elem . dataset_root_path , original_dataset = elem . original_dataset , x = tuple ( new_xs ), y = elem . y , ), cached , ) process ( elem : DatasetElement , force_online : bool = False ) -> tuple [ DatasetElement , bool ] Processes a dataset element and returns an element with the same data, but with the extracted features added to the features dictionary of each image. This method saves the extracted features to the disk, so that they can be loaded later without having to recompute them. This method should not be overridden by the user, but instead the process_element method should be implemented. Parameters: Name Type Description Default elem DatasetElement The dataset element to process. required force_online bool If True, the features are always computed online, even if they have been already computed and saved to the disk. False Returns: Type Description DatasetElement A tuple containing the processed dataset element and a boolean indicating bool whether the feature extraction was loaded from cache. Source code in revelio/feature_extraction/extractor.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 def process ( self , elem : DatasetElement , force_online : bool = False ) -> tuple [ DatasetElement , bool ]: \"\"\" Processes a dataset element and returns an element with the same data, but with the extracted features added to the `features` dictionary of each image. This method saves the extracted features to the disk, so that they can be loaded later without having to recompute them. This method should not be overridden by the user, but instead the `process_element` method should be implemented. Args: elem: The dataset element to process. force_online: If True, the features are always computed online, even if they have been already computed and saved to the disk. Returns: A tuple containing the processed dataset element and a boolean indicating whether the feature extraction was loaded from cache. \"\"\" new_xs = [] cached = True algorithm_name = type ( self ) . __name__ . lower () algorithm_name = algorithm_name . replace ( \"extractor\" , \"\" ) for i , x in enumerate ( elem . x ): features_path = self . _get_features_path ( elem , i ) if features_path . is_file () and not force_online : try : features = np . load ( features_path )[ \"features\" ] except ValueError as e : raise RuntimeError ( f \"Failed to load features: { features_path } \" ) from e new_x = ElementImage ( path = x . path , image = x . image , features = { ** x . features , algorithm_name : features }, ) new_xs . append ( new_x ) else : cached = False try : features = self . process_element ( x ) except Exception as e : raise RuntimeError ( f \"Failed to process { x . path } : { e } \" ) from e if not force_online : # TODO: is it correct? # We don't need to save the features if we're forced to do it online # (that means we have one or more augmentation steps) features_path . parent . mkdir ( parents = True , exist_ok = True ) np . savez_compressed ( features_path , features = features ) new_x = ElementImage ( path = x . path , image = x . image , features = { ** x . features , algorithm_name : features }, ) new_xs . append ( new_x ) return ( DatasetElement ( dataset_root_path = elem . dataset_root_path , original_dataset = elem . original_dataset , x = tuple ( new_xs ), y = elem . y , ), cached , ) process_element ( elem : ElementImage ) -> np . ndarray abstractmethod Processes a single image and returns its features. If the process_element method raises an exception, the dataset element will be skipped and the exception will be logged. Parameters: Name Type Description Default elem ElementImage The image to process. required Returns: Type Description np . ndarray A Numpy array containing the features extracted from the image. Source code in revelio/feature_extraction/extractor.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 @abstractmethod def process_element ( self , elem : ElementImage ) -> np . ndarray : \"\"\" Processes a single image and returns its features. If the `process_element` method raises an exception, the dataset element will be skipped and the exception will be logged. Args: elem: The image to process. Returns: A Numpy array containing the features extracted from the image. \"\"\" raise NotImplementedError # pragma: no cover","title":"extractor"},{"location":"reference/revelio/feature_extraction/extractor/#revelio.feature_extraction.extractor.FeatureExtractor","text":"Bases: Registrable A feature extractor is responsible for extracting various types of features from images. A feature extractor must implement the process_element method, which takes an image and returns the features extracted from it. The features are stored in a dictionary, where the key is the name of the feature extractor (without any \"extractor\" suffixes; e.g. the features produced by a Wavelets Extractor are accessible via the wavelets key) and the value contains the features extracted by the feature extractor. If the process_element method raises an exception, the dataset element will be skipped and the exception will be logged. The process method is responsible for loading the extracted features from the disk, if they have been already computed, or else calling process_element and saving the results. The user should not override this method, but instead implement process_element . Source code in revelio/feature_extraction/extractor.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 class FeatureExtractor ( Registrable ): \"\"\" A feature extractor is responsible for extracting various types of features from images. A feature extractor must implement the `process_element` method, which takes an image and returns the features extracted from it. The features are stored in a dictionary, where the key is the name of the feature extractor (without any \"extractor\" suffixes; e.g. the features produced by a Wavelets Extractor are accessible via the `wavelets` key) and the value contains the features extracted by the feature extractor. If the `process_element` method raises an exception, the dataset element will be skipped and the exception will be logged. The `process` method is responsible for loading the extracted features from the disk, if they have been already computed, or else calling `process_element` and saving the results. The user should not override this method, but instead implement `process_element`. \"\"\" def __init__ ( self , * , _config : Config ) -> None : self . _config = _config def _get_features_path ( self , elem : DatasetElement , x_idx : int ) -> Path : output_path = Path ( self . _config . feature_extraction . output_path ) algorithm_name = type ( self ) . __name__ . lower () relative_img_path = elem . x [ x_idx ] . path . relative_to ( elem . dataset_root_path ) return ( output_path / algorithm_name / elem . original_dataset / relative_img_path . parent / f \" { relative_img_path . stem } .features.npz\" ) @abstractmethod def process_element ( self , elem : ElementImage ) -> np . ndarray : \"\"\" Processes a single image and returns its features. If the `process_element` method raises an exception, the dataset element will be skipped and the exception will be logged. Args: elem: The image to process. Returns: A Numpy array containing the features extracted from the image. \"\"\" raise NotImplementedError # pragma: no cover def process ( self , elem : DatasetElement , force_online : bool = False ) -> tuple [ DatasetElement , bool ]: \"\"\" Processes a dataset element and returns an element with the same data, but with the extracted features added to the `features` dictionary of each image. This method saves the extracted features to the disk, so that they can be loaded later without having to recompute them. This method should not be overridden by the user, but instead the `process_element` method should be implemented. Args: elem: The dataset element to process. force_online: If True, the features are always computed online, even if they have been already computed and saved to the disk. Returns: A tuple containing the processed dataset element and a boolean indicating whether the feature extraction was loaded from cache. \"\"\" new_xs = [] cached = True algorithm_name = type ( self ) . __name__ . lower () algorithm_name = algorithm_name . replace ( \"extractor\" , \"\" ) for i , x in enumerate ( elem . x ): features_path = self . _get_features_path ( elem , i ) if features_path . is_file () and not force_online : try : features = np . load ( features_path )[ \"features\" ] except ValueError as e : raise RuntimeError ( f \"Failed to load features: { features_path } \" ) from e new_x = ElementImage ( path = x . path , image = x . image , features = { ** x . features , algorithm_name : features }, ) new_xs . append ( new_x ) else : cached = False try : features = self . process_element ( x ) except Exception as e : raise RuntimeError ( f \"Failed to process { x . path } : { e } \" ) from e if not force_online : # TODO: is it correct? # We don't need to save the features if we're forced to do it online # (that means we have one or more augmentation steps) features_path . parent . mkdir ( parents = True , exist_ok = True ) np . savez_compressed ( features_path , features = features ) new_x = ElementImage ( path = x . path , image = x . image , features = { ** x . features , algorithm_name : features }, ) new_xs . append ( new_x ) return ( DatasetElement ( dataset_root_path = elem . dataset_root_path , original_dataset = elem . original_dataset , x = tuple ( new_xs ), y = elem . y , ), cached , )","title":"FeatureExtractor"},{"location":"reference/revelio/feature_extraction/extractor/#revelio.feature_extraction.extractor.FeatureExtractor.process","text":"Processes a dataset element and returns an element with the same data, but with the extracted features added to the features dictionary of each image. This method saves the extracted features to the disk, so that they can be loaded later without having to recompute them. This method should not be overridden by the user, but instead the process_element method should be implemented. Parameters: Name Type Description Default elem DatasetElement The dataset element to process. required force_online bool If True, the features are always computed online, even if they have been already computed and saved to the disk. False Returns: Type Description DatasetElement A tuple containing the processed dataset element and a boolean indicating bool whether the feature extraction was loaded from cache. Source code in revelio/feature_extraction/extractor.py 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 def process ( self , elem : DatasetElement , force_online : bool = False ) -> tuple [ DatasetElement , bool ]: \"\"\" Processes a dataset element and returns an element with the same data, but with the extracted features added to the `features` dictionary of each image. This method saves the extracted features to the disk, so that they can be loaded later without having to recompute them. This method should not be overridden by the user, but instead the `process_element` method should be implemented. Args: elem: The dataset element to process. force_online: If True, the features are always computed online, even if they have been already computed and saved to the disk. Returns: A tuple containing the processed dataset element and a boolean indicating whether the feature extraction was loaded from cache. \"\"\" new_xs = [] cached = True algorithm_name = type ( self ) . __name__ . lower () algorithm_name = algorithm_name . replace ( \"extractor\" , \"\" ) for i , x in enumerate ( elem . x ): features_path = self . _get_features_path ( elem , i ) if features_path . is_file () and not force_online : try : features = np . load ( features_path )[ \"features\" ] except ValueError as e : raise RuntimeError ( f \"Failed to load features: { features_path } \" ) from e new_x = ElementImage ( path = x . path , image = x . image , features = { ** x . features , algorithm_name : features }, ) new_xs . append ( new_x ) else : cached = False try : features = self . process_element ( x ) except Exception as e : raise RuntimeError ( f \"Failed to process { x . path } : { e } \" ) from e if not force_online : # TODO: is it correct? # We don't need to save the features if we're forced to do it online # (that means we have one or more augmentation steps) features_path . parent . mkdir ( parents = True , exist_ok = True ) np . savez_compressed ( features_path , features = features ) new_x = ElementImage ( path = x . path , image = x . image , features = { ** x . features , algorithm_name : features }, ) new_xs . append ( new_x ) return ( DatasetElement ( dataset_root_path = elem . dataset_root_path , original_dataset = elem . original_dataset , x = tuple ( new_xs ), y = elem . y , ), cached , )","title":"process()"},{"location":"reference/revelio/feature_extraction/extractor/#revelio.feature_extraction.extractor.FeatureExtractor.process_element","text":"Processes a single image and returns its features. If the process_element method raises an exception, the dataset element will be skipped and the exception will be logged. Parameters: Name Type Description Default elem ElementImage The image to process. required Returns: Type Description np . ndarray A Numpy array containing the features extracted from the image. Source code in revelio/feature_extraction/extractor.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 @abstractmethod def process_element ( self , elem : ElementImage ) -> np . ndarray : \"\"\" Processes a single image and returns its features. If the `process_element` method raises an exception, the dataset element will be skipped and the exception will be logged. Args: elem: The image to process. Returns: A Numpy array containing the features extracted from the image. \"\"\" raise NotImplementedError # pragma: no cover","title":"process_element()"},{"location":"reference/revelio/model/","text":"","title":"model"},{"location":"reference/revelio/model/model/","text":"","title":"model"},{"location":"reference/revelio/model/random_guess/","text":"","title":"random_guess"},{"location":"reference/revelio/model/metrics/","text":"","title":"metrics"},{"location":"reference/revelio/model/metrics/accuracy/","text":"","title":"accuracy"},{"location":"reference/revelio/model/metrics/bpcer_at_apcer/","text":"","title":"bpcer_at_apcer"},{"location":"reference/revelio/model/metrics/eer/","text":"","title":"eer"},{"location":"reference/revelio/model/metrics/metric/","text":"","title":"metric"},{"location":"reference/revelio/model/metrics/tnr/","text":"","title":"tnr"},{"location":"reference/revelio/model/metrics/tpr/","text":"","title":"tpr"},{"location":"reference/revelio/model/metrics/utils/","text":"","title":"utils"},{"location":"reference/revelio/model/nn/","text":"","title":"nn"},{"location":"reference/revelio/model/nn/alexnet/","text":"","title":"alexnet"},{"location":"reference/revelio/model/nn/inception_resnet/","text":"","title":"inception_resnet"},{"location":"reference/revelio/model/nn/mobilenet/","text":"","title":"mobilenet"},{"location":"reference/revelio/model/nn/neuralnet/","text":"","title":"neuralnet"},{"location":"reference/revelio/model/nn/resnet/","text":"","title":"resnet"},{"location":"reference/revelio/model/nn/squeezenet/","text":"","title":"squeezenet"},{"location":"reference/revelio/model/nn/utils/","text":"","title":"utils"},{"location":"reference/revelio/model/nn/vgg/","text":"","title":"vgg"},{"location":"reference/revelio/model/nn/vision_transformer/","text":"","title":"vision_transformer"},{"location":"reference/revelio/model/nn/callbacks/","text":"","title":"callbacks"},{"location":"reference/revelio/model/nn/callbacks/callback/","text":"","title":"callback"},{"location":"reference/revelio/model/nn/callbacks/early_stopping/","text":"","title":"early_stopping"},{"location":"reference/revelio/model/nn/callbacks/model_checkpoint/","text":"","title":"model_checkpoint"},{"location":"reference/revelio/model/nn/callbacks/tensorboard/","text":"","title":"tensorboard"},{"location":"reference/revelio/model/nn/losses/","text":"","title":"losses"},{"location":"reference/revelio/model/nn/losses/loss/","text":"","title":"loss"},{"location":"reference/revelio/model/nn/losses/losses/","text":"","title":"losses"},{"location":"reference/revelio/model/nn/optimizers/","text":"","title":"optimizers"},{"location":"reference/revelio/model/nn/optimizers/optimizer/","text":"","title":"optimizer"},{"location":"reference/revelio/model/nn/optimizers/optimizers/","text":"","title":"optimizers"},{"location":"reference/revelio/preprocessing/","text":"","title":"preprocessing"},{"location":"reference/revelio/preprocessing/normalize/","text":"","title":"normalize"},{"location":"reference/revelio/preprocessing/resize/","text":"","title":"resize"},{"location":"reference/revelio/preprocessing/step/","text":"PreprocessingStep Bases: Registrable A preprocessing step is applied to all dataset elements before they are passed to the model, and can be used to perform any preprocessing that is not part of the model itself (e.g. resizing, cropping, normalization, etc.). The process_element method is called for each image of the dataset element. A preprocessing step must implement the process_element method, which takes an image and returns its preprocessed version. Source code in revelio/preprocessing/step.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 class PreprocessingStep ( Registrable ): \"\"\" A preprocessing step is applied to all dataset elements before they are passed to the model, and can be used to perform any preprocessing that is not part of the model itself (e.g. resizing, cropping, normalization, etc.). The `process_element` method is called for each image of the dataset element. A preprocessing step must implement the `process_element` method, which takes an image and returns its preprocessed version. \"\"\" @abstractmethod def process_element ( self , elem : ElementImage ) -> ElementImage : \"\"\" Processes a single image of a dataset element, and returns its preprocessed version. Args: elem: The image to be preprocessed. Returns: The preprocessed image. \"\"\" raise NotImplementedError # pragma: no cover def process ( self , elem : DatasetElement ) -> DatasetElement : \"\"\" Processes a dataset element, and returns its preprocessed version. This method should not be overridden by the user, but instead the `process_element` method should be implemented. Args: elem: The dataset element to be preprocessed. Returns: The preprocessed dataset element. \"\"\" new_xs = [ self . process_element ( x ) for x in elem . x ] return DatasetElement ( dataset_root_path = elem . dataset_root_path , original_dataset = elem . original_dataset , x = tuple ( new_xs ), y = elem . y , ) process ( elem : DatasetElement ) -> DatasetElement Processes a dataset element, and returns its preprocessed version. This method should not be overridden by the user, but instead the process_element method should be implemented. Parameters: Name Type Description Default elem DatasetElement The dataset element to be preprocessed. required Returns: Type Description DatasetElement The preprocessed dataset element. Source code in revelio/preprocessing/step.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def process ( self , elem : DatasetElement ) -> DatasetElement : \"\"\" Processes a dataset element, and returns its preprocessed version. This method should not be overridden by the user, but instead the `process_element` method should be implemented. Args: elem: The dataset element to be preprocessed. Returns: The preprocessed dataset element. \"\"\" new_xs = [ self . process_element ( x ) for x in elem . x ] return DatasetElement ( dataset_root_path = elem . dataset_root_path , original_dataset = elem . original_dataset , x = tuple ( new_xs ), y = elem . y , ) process_element ( elem : ElementImage ) -> ElementImage abstractmethod Processes a single image of a dataset element, and returns its preprocessed version. Parameters: Name Type Description Default elem ElementImage The image to be preprocessed. required Returns: Type Description ElementImage The preprocessed image. Source code in revelio/preprocessing/step.py 19 20 21 22 23 24 25 26 27 28 29 30 31 @abstractmethod def process_element ( self , elem : ElementImage ) -> ElementImage : \"\"\" Processes a single image of a dataset element, and returns its preprocessed version. Args: elem: The image to be preprocessed. Returns: The preprocessed image. \"\"\" raise NotImplementedError # pragma: no cover","title":"step"},{"location":"reference/revelio/preprocessing/step/#revelio.preprocessing.step.PreprocessingStep","text":"Bases: Registrable A preprocessing step is applied to all dataset elements before they are passed to the model, and can be used to perform any preprocessing that is not part of the model itself (e.g. resizing, cropping, normalization, etc.). The process_element method is called for each image of the dataset element. A preprocessing step must implement the process_element method, which takes an image and returns its preprocessed version. Source code in revelio/preprocessing/step.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 class PreprocessingStep ( Registrable ): \"\"\" A preprocessing step is applied to all dataset elements before they are passed to the model, and can be used to perform any preprocessing that is not part of the model itself (e.g. resizing, cropping, normalization, etc.). The `process_element` method is called for each image of the dataset element. A preprocessing step must implement the `process_element` method, which takes an image and returns its preprocessed version. \"\"\" @abstractmethod def process_element ( self , elem : ElementImage ) -> ElementImage : \"\"\" Processes a single image of a dataset element, and returns its preprocessed version. Args: elem: The image to be preprocessed. Returns: The preprocessed image. \"\"\" raise NotImplementedError # pragma: no cover def process ( self , elem : DatasetElement ) -> DatasetElement : \"\"\" Processes a dataset element, and returns its preprocessed version. This method should not be overridden by the user, but instead the `process_element` method should be implemented. Args: elem: The dataset element to be preprocessed. Returns: The preprocessed dataset element. \"\"\" new_xs = [ self . process_element ( x ) for x in elem . x ] return DatasetElement ( dataset_root_path = elem . dataset_root_path , original_dataset = elem . original_dataset , x = tuple ( new_xs ), y = elem . y , )","title":"PreprocessingStep"},{"location":"reference/revelio/preprocessing/step/#revelio.preprocessing.step.PreprocessingStep.process","text":"Processes a dataset element, and returns its preprocessed version. This method should not be overridden by the user, but instead the process_element method should be implemented. Parameters: Name Type Description Default elem DatasetElement The dataset element to be preprocessed. required Returns: Type Description DatasetElement The preprocessed dataset element. Source code in revelio/preprocessing/step.py 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def process ( self , elem : DatasetElement ) -> DatasetElement : \"\"\" Processes a dataset element, and returns its preprocessed version. This method should not be overridden by the user, but instead the `process_element` method should be implemented. Args: elem: The dataset element to be preprocessed. Returns: The preprocessed dataset element. \"\"\" new_xs = [ self . process_element ( x ) for x in elem . x ] return DatasetElement ( dataset_root_path = elem . dataset_root_path , original_dataset = elem . original_dataset , x = tuple ( new_xs ), y = elem . y , )","title":"process()"},{"location":"reference/revelio/preprocessing/step/#revelio.preprocessing.step.PreprocessingStep.process_element","text":"Processes a single image of a dataset element, and returns its preprocessed version. Parameters: Name Type Description Default elem ElementImage The image to be preprocessed. required Returns: Type Description ElementImage The preprocessed image. Source code in revelio/preprocessing/step.py 19 20 21 22 23 24 25 26 27 28 29 30 31 @abstractmethod def process_element ( self , elem : ElementImage ) -> ElementImage : \"\"\" Processes a single image of a dataset element, and returns its preprocessed version. Args: elem: The image to be preprocessed. Returns: The preprocessed image. \"\"\" raise NotImplementedError # pragma: no cover","title":"process_element()"},{"location":"reference/revelio/preprocessing/to_float/","text":"","title":"to_float"},{"location":"reference/revelio/registry/","text":"","title":"registry"},{"location":"reference/revelio/registry/registry/","text":"","title":"registry"},{"location":"reference/revelio/utils/","text":"","title":"utils"},{"location":"reference/revelio/utils/iterators/","text":"","title":"iterators"},{"location":"reference/revelio/utils/logging/","text":"","title":"logging"},{"location":"reference/revelio/utils/random/","text":"","title":"random"},{"location":"reference/revelio/utils/rounding/","text":"","title":"rounding"}]}